{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytreeLSTMCell():\n",
    "    def __init__(self, weight_ih, weight_hh, bias):\n",
    "        self.weight_ih = weight_ih\n",
    "        self.weight_hh = weight_hh\n",
    "        self.bias = bias\n",
    "\n",
    "    def __call__(self, inputs, h, c):\n",
    "        ifgo = self.weight_ih @ inputs + self.weight_hh @ h + self.bias\n",
    "        i, f, g, o = jnp.split(ifgo, indices_or_sections=4, axis=-1)\n",
    "        i = jax.nn.sigmoid(i)\n",
    "        f = jax.nn.sigmoid(f)\n",
    "        g = jnp.tanh(g)\n",
    "        o = jax.nn.sigmoid(o)\n",
    "        new_c = f * c + i * g\n",
    "        new_h = o * jnp.tanh(new_c)\n",
    "        return (new_h, new_c)\n",
    "\n",
    "jax.tree_util.register_pytree_node(\n",
    "    PytreeLSTMCell,\n",
    "    lambda c: ((c.weight_ih, c.weight_hh, c.bias), None),\n",
    "    lambda _, ws: PytreeLSTMCell(*ws),\n",
    ")\n",
    "\n",
    "class PytreeLSTMLM():\n",
    "    def __init__(self, cell, embeddings, c_0):\n",
    "        self.cell = cell\n",
    "        self.embeddings = embeddings\n",
    "        self.c_0 = c_0\n",
    "    \n",
    "    @property\n",
    "    def hc_0(self):\n",
    "        return (jnp.tanh(self.c_0), self.c_0)\n",
    "\n",
    "    @jax.jit\n",
    "    def forward(self, seq, hc):\n",
    "        loss = 0.\n",
    "        for idx in seq:\n",
    "            loss -= jax.nn.log_softmax(self.embeddings @ hc[0])[idx]\n",
    "            hc = self.cell(self.embeddings[idx,:], *hc)\n",
    "        return loss, hc\n",
    "\n",
    "    def greedy_argmax(self, hc, length=6):\n",
    "        idxs = []\n",
    "        for i in range(length):\n",
    "            idx = jnp.argmax(self.embeddings @ hc[0])\n",
    "            idxs.append(int(idx))\n",
    "            hc = self.cell(self.embeddings[idx,:], *hc)\n",
    "        return idxs\n",
    "\n",
    "# only need to return lm.cell, tree_map is clever enough to flatten/unflatten recursively.\n",
    "def flatten_whole_lstmlm(lm):\n",
    "    return (lm.cell, lm.embeddings, lm.c_0), None\n",
    "\n",
    "def unflatten_whole_lstmlm(aux, weights):\n",
    "    return PytreeLSTMLM(*weights)\n",
    "\n",
    "jax.tree_util.register_pytree_node(\n",
    "    PytreeLSTMLM,\n",
    "    flatten_whole_lstmlm,\n",
    "    unflatten_whole_lstmlm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 43\n",
    "hid_dim = 17\n",
    "lm = PytreeLSTMLM(\n",
    "    PytreeLSTMCell(\n",
    "        jax.random.uniform(jax.random.PRNGKey(1234), (4*hid_dim, hid_dim)),\n",
    "        jax.random.uniform(jax.random.PRNGKey(4321), (4*hid_dim, hid_dim)),\n",
    "        jnp.zeros((4*hid_dim,)),\n",
    "    ),\n",
    "    jax.random.uniform(jax.random.PRNGKey(123), (vocab_size, hid_dim)),\n",
    "    jnp.zeros((hid_dim,)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTreeDef(CustomNode(PytreeLSTMLM[None], [CustomNode(PytreeLSTMCell[None], [*, *, *]), *, *]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_util.tree_structure(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = jnp.array([4, 8, 15, 16, 23, 42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_combiner = lambda p, g: p - 0.1*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample before: [0, 25, 25, 25, 25, 25]\n",
      "Loss: 26.58103370666504\n",
      "Loss: 4.404338717460632\n",
      "Loss: 2.6979196071624756\n",
      "Sample after: [4, 8, 15, 16, 23, 42]\n"
     ]
    }
   ],
   "source": [
    "def pure_loss_fn(lm, seq, hc):\n",
    "    if hc is None:\n",
    "        hc = lm.hc_0\n",
    "    loss, hc = lm.forward(seq, hc)\n",
    "    return loss,hc\n",
    "\n",
    "grad_fn = jax.value_and_grad(pure_loss_fn,has_aux=True)\n",
    "\n",
    "print(\"Sample before:\", lm.greedy_argmax(lm.hc_0))\n",
    "\n",
    "bptt_length = 3\n",
    "for epoch in range(101):\n",
    "    totalloss = 0.\n",
    "    hc = None\n",
    "    for start in range(0, len(training_data), bptt_length):\n",
    "        batch = training_data[start:start+bptt_length]\n",
    "        (loss,hc),grad_lm = grad_fn(lm, batch, hc)\n",
    "        if epoch % 50 == 0:\n",
    "            totalloss += loss.item()\n",
    "        lm = jax.tree_map(update_combiner, lm, grad_lm)\n",
    "    if totalloss:\n",
    "        print(\"Loss:\", totalloss)\n",
    "\n",
    "print(\"Sample after:\", lm.greedy_argmax(lm.hc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
