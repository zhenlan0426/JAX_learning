{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc871d51-f6a5-4891-964a-2c8ee6406e85",
    "_uuid": "733718da-4b3b-45b9-85a9-2dba8234961a",
    "papermill": {
     "duration": 0.040794,
     "end_time": "2022-01-04T19:06:57.340525",
     "exception": false,
     "start_time": "2022-01-04T19:06:57.299731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modified based on https://www.kaggle.com/code/aakashnain/building-models-in-jax-part2-flax#Evaluation\n",
    "\n",
    "Showcase:\n",
    "1. Train model with BatchNorm and Dropout (how to track/update states for BN and how to update key for dropout)\n",
    "2. Train_one_step & eval_one_step\n",
    "3. How to change between Training and Eval mode\n",
    "4. Use pmap to leverage 8 TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7fbb7eb7-f444-4ad7-8964-cfb52a8d52dc",
    "_uuid": "9fd12164-1f03-4f72-9f0b-bb580168eb5d",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:31:16.542000Z",
     "iopub.status.busy": "2023-07-15T17:31:16.541652Z",
     "iopub.status.idle": "2023-07-15T17:31:16.553478Z",
     "shell.execute_reply": "2023-07-15T17:31:16.552725Z",
     "shell.execute_reply.started": "2023-07-15T17:31:16.541971Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7ac4c4c3-3515-46c0-aef9-fe782264b61c",
    "_uuid": "129d809d-7bd2-48f0-b660-74894300d007",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:31:16.555598Z",
     "iopub.status.busy": "2023-07-15T17:31:16.555199Z",
     "iopub.status.idle": "2023-07-15T17:31:50.223562Z",
     "shell.execute_reply": "2023-07-15T17:31:50.222440Z",
     "shell.execute_reply.started": "2023-07-15T17:31:16.555570Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.602287,
     "end_time": "2022-01-04T19:07:04.983064",
     "exception": false,
     "start_time": "2022-01-04T19:06:57.380777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from flax.core import freeze, unfreeze\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import make_jaxpr\n",
    "from jax.config import config\n",
    "from jax import value_and_grad\n",
    "from jax import grad, vmap, pmap, jit\n",
    "\n",
    "import optax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "n_devices = len(jax.devices())\n",
    "np.random.seed(1234)\n",
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8acd171d-ed7b-492b-b5a2-8c14c2880481",
    "_uuid": "c999a9db-319a-41e2-aec7-ce55b90790d7",
    "papermill": {
     "duration": 0.022962,
     "end_time": "2022-01-04T19:07:05.029004",
     "exception": false,
     "start_time": "2022-01-04T19:07:05.006042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset\n",
    "\n",
    "We will use the Cifar-10 dataset for this experiment. You can download it or add it from Kaggle as well, but I am directly importing it from the available `tf.keras.datasets` for the sake of simplicity and brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "1db91737-1f04-41b1-8dd3-07085c6556c1",
    "_uuid": "77587660-6e74-4a56-ad6b-0304faad2162",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:31:50.225236Z",
     "iopub.status.busy": "2023-07-15T17:31:50.224740Z",
     "iopub.status.idle": "2023-07-15T17:31:51.022798Z",
     "shell.execute_reply": "2023-07-15T17:31:51.021667Z",
     "shell.execute_reply.started": "2023-07-15T17:31:50.225206Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.318512,
     "end_time": "2022-01-04T19:07:14.370367",
     "exception": false,
     "start_time": "2022-01-04T19:07:05.051855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training samples: 50000 with samples shape: (32, 32, 3)\n",
      "Number of validation samples: 10000 with samples shape: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# The downloaded dataset consists of two tuples. The first\n",
    "# tuple represents the training data consisting of pairs of images\n",
    "# and labels. Similary, the second tuple consists of validation/test data.\n",
    "# I will use the second tuple as the validation data for this demo\n",
    "\n",
    "(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\n",
    "print(f\"\\nNumber of training samples: {len(x_train)} with samples shape: {x_train.shape[1:]}\")\n",
    "print(f\"Number of validation samples: {len(x_valid)} with samples shape: {x_valid.shape[1:]}\")\n",
    "\n",
    "\n",
    "# There are 10 classes in this dataset. We will create a dictionary for\n",
    "# mapping the names of the classes represented by the integer labels\n",
    "# Labels dictionary\n",
    "labels_dict = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "44281089-a7dd-455e-a6f3-5f99767ba89c",
    "_uuid": "09a0ccc7-52a9-4c53-9f70-b2a9567a5fb1",
    "papermill": {
     "duration": 0.061566,
     "end_time": "2022-01-04T19:07:21.850018",
     "exception": false,
     "start_time": "2022-01-04T19:07:21.788452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Perfect! The augmentation pipeline is working as expected. Let's move to the next step.\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "For data preprocessing, we will apply these two things:\n",
    "1. We will normalize the image data so that the pixel values for each image is in the range `[0, 1]`\n",
    "2. We will one-hot encode our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "3431835d-8185-46b5-b54f-ac708807e0f0",
    "_uuid": "65f6ac52-acc5-43a6-9c60-6d2a30ccd97a",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:31:51.024179Z",
     "iopub.status.busy": "2023-07-15T17:31:51.023895Z",
     "iopub.status.idle": "2023-07-15T17:31:52.251061Z",
     "shell.execute_reply": "2023-07-15T17:31:52.249913Z",
     "shell.execute_reply.started": "2023-07-15T17:31:51.024152Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.688759,
     "end_time": "2022-01-04T19:07:24.600434",
     "exception": false,
     "start_time": "2022-01-04T19:07:21.911675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1228800000 bytes == 0x99484000 @  0x7f97508e6680 0x7f9750907824 0x7f97476c4a44 0x7f97476c51df 0x7f9747722e75 0x7f9747722fd6 0x7f97477d4b46 0x7f97477d82d5 0x7f97478cc07a 0x7f97478d533e 0x634fbd 0x711b7c 0x7f97477de65c 0x641d66 0x58bcde 0x6da3bf 0x6da647 0x6dc2b3 0x58e8d5 0x70b63c 0x63f58e 0x58dffe 0x70b63c 0x63f58e 0x58dffe 0x70b63c 0x70b8d7 0x6251f7 0x635d05 0x58b1da 0x5644be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape:   (50000, 32, 32, 3)  Labels shape: (50000, 10)\n",
      "Validation images shape: (10000, 32, 32, 3)  Labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the image pixels in the range [0, 1]\n",
    "x_train_normalized = jnp.array(x_train / 255.)\n",
    "x_valid_normalized = jnp.array(x_valid / 255.)\n",
    "\n",
    "# One hot encoding applied to the labels. We have 10\n",
    "# classes in the dataset, hence the depth of OHE would be 10\n",
    "y_train_ohe = jnp.squeeze(jax.nn.one_hot(y_train, num_classes=10))\n",
    "y_valid_ohe = jnp.squeeze(jax.nn.one_hot(y_valid, num_classes=10))\n",
    "\n",
    "print(f\"Training images shape:   {x_train_normalized.shape}  Labels shape: {y_train_ohe.shape}\")\n",
    "print(f\"Validation images shape: {x_valid_normalized.shape}  Labels shape: {y_valid_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98409ea4-132d-4555-acda-abf0d1992f94",
    "_uuid": "dcc21ac1-f547-403c-89e7-ff9d6eca5c35",
    "papermill": {
     "duration": 0.060709,
     "end_time": "2022-01-04T19:07:24.724781",
     "exception": false,
     "start_time": "2022-01-04T19:07:24.664072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Generator\n",
    "\n",
    "Now that we have preprocessed our dataset, we need to define our data generator that will stream batches of data, where each batch is a pair of images and the corresponding labels. We will apply data augmentation to the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "7f76ede5-8471-4920-9e5a-03d235161267",
    "_uuid": "4daf4b27-c7de-42c2-a0ce-6ec67a227ec5",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:31:52.254001Z",
     "iopub.status.busy": "2023-07-15T17:31:52.253582Z",
     "iopub.status.idle": "2023-07-15T17:31:52.266941Z",
     "shell.execute_reply": "2023-07-15T17:31:52.265821Z",
     "shell.execute_reply.started": "2023-07-15T17:31:52.253970Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.068589,
     "end_time": "2022-01-04T19:07:25.852618",
     "exception": false,
     "start_time": "2022-01-04T19:07:24.784029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identity(img):\n",
    "    \"\"\"Returns an image as it is.\"\"\"\n",
    "    return img\n",
    "\n",
    "\n",
    "def flip_left_right(img):\n",
    "    \"\"\"Flips an image left/right direction.\"\"\"\n",
    "    return jnp.fliplr(img)\n",
    "\n",
    "\n",
    "def random_horizontal_flip(img, flip):\n",
    "    \"\"\"Randomly flip an image vertically.\n",
    "    \n",
    "    Args:\n",
    "        img: Array representing the image\n",
    "        flip: Boolean for flipping or not\n",
    "    Returns:\n",
    "        Flipped or an identity image\n",
    "    \"\"\"\n",
    "    \n",
    "    return jax.lax.cond(flip, flip_left_right, identity, img)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# All the above function are written to work on a single example. \n",
    "# We will use `vmap` to get a version of these functions that can\n",
    "# operate on a batch of images. We will also add the `jit` transformation\n",
    "# on top of it so that the whole pipeline can be compiled and executed faster\n",
    "random_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def augment_images(images, key):\n",
    "    \"\"\"Augment a batch of input images.\n",
    "    \n",
    "    Args:\n",
    "        images: Batch of input images as a jax array\n",
    "        key: Seed/Key for random functions for generating booleans\n",
    "    Returns:\n",
    "        Augmented images with the same shape as the input images\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = len(images)\n",
    "    \n",
    "    # 2. Flip horizontally\n",
    "    key, subkey = random.split(key)\n",
    "    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n",
    "    augmented = random_horizontal_flip_jitted(images, flip)\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "0fa7a95a-df7d-4707-9322-80db4308a782",
    "_uuid": "ea2497a5-0f37-47de-86e9-04dbef37fb94",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:32:11.624928Z",
     "iopub.status.busy": "2023-07-15T17:32:11.624571Z",
     "iopub.status.idle": "2023-07-15T17:32:11.646578Z",
     "shell.execute_reply": "2023-07-15T17:32:11.645347Z",
     "shell.execute_reply.started": "2023-07-15T17:32:11.624898Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images is of shape:  (8, 32, 32, 3)\n",
      "Batch of labels is of shape:  (8, 10)\n"
     ]
    }
   ],
   "source": [
    "def data_generator(images, labels, batch_size=128, is_valid=False, key=None):\n",
    "    \"\"\"Generates batches of data from a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        images: Image data represented by a ndarray\n",
    "        labels: One-hot enocded labels\n",
    "        batch_size: Number of data points in a single batch\n",
    "        is_valid: (Boolean) If validation data, then don't shuffle and\n",
    "                    don't apply any augmentation\n",
    "        key: PRNG key needed for augmentation\n",
    "    Yields:\n",
    "        Batches of images-labels pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate the total number of batches\n",
    "    num_batches = int(np.ceil(len(images) / batch_size))\n",
    "    \n",
    "    # 2. Get the indices and shuffle them\n",
    "    indices = np.arange(len(images))\n",
    "    \n",
    "    if not is_valid:\n",
    "        if key is None:\n",
    "             raise ValueError(\"A PRNG key is required if `aug` is set to True\")\n",
    "        else:\n",
    "            np.random.shuffle(indices)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        curr_idx = indices[batch * batch_size: (batch+1) * batch_size]\n",
    "        batch_images = images[curr_idx]\n",
    "        batch_labels = labels[curr_idx]\n",
    "        \n",
    "        if not is_valid: \n",
    "            batch_images = augment_images(batch_images, key=key)\n",
    "        yield batch_images, batch_labels\n",
    "        \n",
    "        \n",
    "\n",
    "# Sanity Check: To make sure that the batches generated by the data\n",
    "# generator are of correct size, we will just pull a batch of data and\n",
    "# will check the shape of the images and the labels\n",
    "\n",
    "sample_data_gen = data_generator(\n",
    "    images=x_train_normalized,\n",
    "    labels=y_train_ohe,\n",
    "    batch_size=8,\n",
    "    is_valid=False,\n",
    "    key=random.PRNGKey(0)\n",
    ")\n",
    "\n",
    "sample_batch_images, sample_batch_labels = next(sample_data_gen)\n",
    "print(\"Batch of images is of shape: \", sample_batch_images.shape)\n",
    "print(\"Batch of labels is of shape: \", sample_batch_labels.shape)\n",
    "\n",
    "# Clean up unnecessary objects\n",
    "del sample_data_gen, sample_batch_images, sample_batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f839330c-14f5-4be3-af55-7189cf059f4b",
    "_uuid": "549a3efa-0784-4df8-87fb-b9054dc8750e",
    "papermill": {
     "duration": 0.059208,
     "end_time": "2022-01-04T19:07:25.972317",
     "exception": false,
     "start_time": "2022-01-04T19:07:25.913109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "e0c562b4-0e66-4098-addc-9f88e3d369bd",
    "_uuid": "f073b37b-657a-45c6-8061-60cd3d242eeb",
    "execution": {
     "iopub.execute_input": "2023-07-15T17:32:14.275797Z",
     "iopub.status.busy": "2023-07-15T17:32:14.274895Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class resNet(nn.Module):\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, IsTrain):\n",
    "        x = inputs\n",
    "        x = nn.Conv(x.shape[-1], (3, 3), padding=\"SAME\",use_bias=False)(x)\n",
    "        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n",
    "        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n",
    "        x = nn.gelu(x)\n",
    "        return inputs + x\n",
    "\n",
    "class Pool(nn.Module):\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, IsTrain):\n",
    "        x = nn.Conv(inputs.shape[-1]*4, (3, 3), (2, 2), padding=\"SAME\",use_bias=False)(inputs)\n",
    "        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n",
    "        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n",
    "        x = nn.gelu(x)\n",
    "        return x\n",
    "    \n",
    "class CifarCNN(nn.Module):\n",
    "    \"\"\"CIFAR-10 Classifier\"\"\"\n",
    "    res_repeats: int = 3\n",
    "    out_repeats: int = 4\n",
    "    @nn.compact\n",
    "    def __call__(self, x, IsTrain):\n",
    "        x = Pool()(x,IsTrain)\n",
    "        for _ in range(self.out_repeats):\n",
    "            x = Pool()(x,IsTrain)\n",
    "            for _ in range(self.res_repeats):\n",
    "                x = resNet()(x,IsTrain)\n",
    "        # Flatten \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # Dense layers\n",
    "        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n",
    "        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n",
    "        # We are going to return the logits and not\n",
    "        # the softamx activations \n",
    "        x = nn.Dense(10)(x)\n",
    "        return x\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128 * 8\n",
    "num_train_batches = len(x_train) // BATCH_SIZE\n",
    "num_valid_batches = len(x_valid) // BATCH_SIZE\n",
    "total_steps = EPOCHS * num_train_batches\n",
    "\n",
    "model = CifarCNN()\n",
    "params = model.init({'params':random.PRNGKey(2),'dropout':random.PRNGKey(3)},jnp.ones([1, 32, 32, 3]),True)\n",
    "states,params = params.pop('params')\n",
    "# _scheduler = optax.piecewise_constant_schedule(init_value=1e-2,\n",
    "#                                                boundaries_and_scales={int(total_steps*0.6):0.25,\n",
    "#                                                                       int(total_steps*0.85):0.25})\n",
    "opt = optax.adamw(learning_rate=1e-2)\n",
    "opt_states = opt.init(params)\n",
    "combined_states = freeze({'params':params,**states})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d28110b-4584-4109-ab11-b161356ff230",
    "_uuid": "f6ca0ba1-ee64-48d0-b125-9ec6f3f1e194"
   },
   "source": [
    "# Training\n",
    "\n",
    "We have coded every piece required for training and evaluation. We will now define our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "5a2812a2-8c5f-49e9-bdec-44de1237beb6",
    "_uuid": "1cc52928-3e63-4ba4-8050-af709a32a5ba",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_one_step(x,y,combined_states,opt_states,dropout_key):\n",
    "    # bring grads back to host for updates. only pmap grad_fn\n",
    "    return_key,*dropout_key = random.split(dropout_key,n_devices+1)\n",
    "    dropout_key = jnp.stack(dropout_key)\n",
    "    states,params = combined_states.pop('params')\n",
    "    def loss_fn(params,states,dropout_key,x,y):\n",
    "        yhat,new_states = model.apply({'params':params,**states},x,True,\\\n",
    "                                   mutable='batch_stats',rngs={'dropout':dropout_key})\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n",
    "        metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n",
    "        return loss,(new_states,metric)\n",
    "    grad_fn = pmap(jax.value_and_grad(loss_fn,has_aux=True),axis_name='device',in_axes=(None,None,0,0,0))\n",
    "    out = grad_fn(params,states,dropout_key,x,y)\n",
    "    (l,(states,metric)),grads = jax.tree_map(lambda x:x.mean(0),out)\n",
    "    updates, opt_states = opt.update(grads, opt_states,params=params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    combined_states = freeze({'params':params,**states})\n",
    "    return combined_states,opt_states,return_key,l,metric\n",
    "\n",
    "@jax.jit\n",
    "def eval_one_step(x,y,combined_states):\n",
    "    yhat = model.apply(combined_states,x,False)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n",
    "    metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n",
    "    return loss, metric\n",
    "\n",
    "psplit = lambda x: x.reshape(n_devices,BATCH_SIZE//n_devices,*x.shape[1:])\n",
    "\n",
    "@partial(pmap,axis_name='device',in_axes=(0,0,None,None,0),out_axes=(None,None,0,None,None))\n",
    "def train_one_step2(x,y,combined_states,opt_states,dropout_key):\n",
    "    # do everything on devices. Just need to sync grads,states\n",
    "    return_key,dropout_key = random.split(dropout_key,2)\n",
    "    states,params = combined_states.pop('params')\n",
    "    def loss_fn(params,states,dropout_key,x,y):\n",
    "        yhat,new_states = model.apply({'params':params,**states},x,True,\\\n",
    "                                   mutable='batch_stats',rngs={'dropout':dropout_key})\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n",
    "        metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n",
    "        return loss,(new_states,metric)\n",
    "    grad_fn = jax.value_and_grad(loss_fn,has_aux=True)\n",
    "    out = grad_fn(params,states,dropout_key,x,y)\n",
    "    (l,(states,metric)),grads = jax.lax.pmean(out,'device')\n",
    "    updates, opt_states = opt.update(grads, opt_states,params=params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    combined_states = freeze({'params':params,**states})\n",
    "    return combined_states,opt_states,return_key,l,metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Error loading program: Attempting to reserve 5.08G at the bottom of memory. That was not possible. There are 4.86G free, 0B reserved, and 4.86G reservable.: while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m x,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_data_gen)\n\u001b[1;32m     24\u001b[0m x,y \u001b[38;5;241m=\u001b[39m psplit(x),psplit(y)\n\u001b[0;32m---> 25\u001b[0m combined_states,opt_states,dropout_key,l,metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcombined_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdropout_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m train_batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\n\u001b[1;32m     27\u001b[0m train_batch_metric \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.venv311/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1349\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(\n\u001b[1;32m   1345\u001b[0m       results\u001b[38;5;241m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1346\u001b[0m           \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects)),\n\u001b[1;32m   1347\u001b[0m       results\u001b[38;5;241m.\u001b[39mconsume_token())\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1351\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Error loading program: Attempting to reserve 5.08G at the bottom of memory. That was not possible. There are 4.86G free, 0B reserved, and 4.86G reservable.: while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well)."
     ]
    }
   ],
   "source": [
    "import time\n",
    "since = time.time()\n",
    "key = random.PRNGKey(0)\n",
    "key, dropout_key = random.split(key)\n",
    "\n",
    "    \n",
    "for i in range(EPOCHS):\n",
    "    train_data_gen = data_generator(x_train_normalized,\n",
    "                            y_train_ohe,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            is_valid=False,\n",
    "                            key=key\n",
    "                           )\n",
    "    valid_data_gen = data_generator(x_valid_normalized,\n",
    "                               y_valid_ohe,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               is_valid=True\n",
    "                               )\n",
    "    # train\n",
    "    train_batch_loss = 0\n",
    "    train_batch_metric = 0\n",
    "    for step in range(num_train_batches):\n",
    "        x,y = next(train_data_gen)\n",
    "        x,y = psplit(x),psplit(y)\n",
    "        combined_states,opt_states,dropout_key,l,metric = train_one_step(x,y,combined_states,opt_states,dropout_key)\n",
    "        train_batch_loss += l\n",
    "        train_batch_metric += metric\n",
    "    train_batch_loss/=num_train_batches\n",
    "    train_batch_metric/=num_train_batches\n",
    "    \n",
    "    # eval\n",
    "    eval_batch_loss = 0\n",
    "    eval_batch_metric = 0\n",
    "    for step in range(num_valid_batches):\n",
    "        x,y = next(valid_data_gen)\n",
    "        loss, metric = eval_one_step(x,y,combined_states)\n",
    "        eval_batch_loss += l\n",
    "        eval_batch_metric += metric\n",
    "    eval_batch_loss/=num_valid_batches\n",
    "    eval_batch_metric/=num_valid_batches\n",
    "    \n",
    "    print(f\"epoch:{i}, loss: {train_batch_loss:.3f}, acc: {train_batch_metric:.3f}, valid_loss: {eval_batch_loss:.3f}, valid_acc: {eval_batch_metric:.3f}\")\n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}min'.format(time_elapsed/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d22296af-b4b1-4a58-b873-fc0d677ef099",
    "_uuid": "e723d24b-d367-4c6d-9a59-f3ab5effcb50",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss: 3.989, acc: 0.122, valid_loss: 3.462, valid_acc: 0.105\n",
      "epoch:1, loss: 2.534, acc: 0.202, valid_loss: 2.055, valid_acc: 0.174\n",
      "epoch:2, loss: 2.372, acc: 0.256, valid_loss: 2.487, valid_acc: 0.170\n",
      "epoch:3, loss: 2.081, acc: 0.319, valid_loss: 2.027, valid_acc: 0.150\n",
      "epoch:4, loss: 1.766, acc: 0.375, valid_loss: 1.591, valid_acc: 0.224\n",
      "epoch:5, loss: 1.685, acc: 0.421, valid_loss: 1.720, valid_acc: 0.295\n",
      "epoch:6, loss: 2.120, acc: 0.359, valid_loss: 1.832, valid_acc: 0.151\n",
      "epoch:7, loss: 2.059, acc: 0.365, valid_loss: 1.832, valid_acc: 0.138\n",
      "epoch:8, loss: 1.679, acc: 0.420, valid_loss: 1.660, valid_acc: 0.389\n",
      "epoch:9, loss: 1.508, acc: 0.466, valid_loss: 1.440, valid_acc: 0.455\n",
      "epoch:10, loss: 1.416, acc: 0.492, valid_loss: 1.325, valid_acc: 0.458\n",
      "epoch:11, loss: 1.326, acc: 0.523, valid_loss: 1.340, valid_acc: 0.470\n",
      "epoch:12, loss: 1.289, acc: 0.547, valid_loss: 1.211, valid_acc: 0.494\n",
      "epoch:13, loss: 1.240, acc: 0.564, valid_loss: 1.181, valid_acc: 0.519\n",
      "epoch:14, loss: 1.173, acc: 0.582, valid_loss: 1.152, valid_acc: 0.541\n",
      "epoch:15, loss: 1.123, acc: 0.601, valid_loss: 1.154, valid_acc: 0.555\n",
      "epoch:16, loss: 1.116, acc: 0.614, valid_loss: 1.134, valid_acc: 0.542\n",
      "epoch:17, loss: 1.061, acc: 0.626, valid_loss: 0.980, valid_acc: 0.612\n",
      "epoch:18, loss: 0.980, acc: 0.652, valid_loss: 0.997, valid_acc: 0.599\n",
      "epoch:19, loss: 0.939, acc: 0.664, valid_loss: 0.921, valid_acc: 0.640\n",
      "epoch:20, loss: 0.881, acc: 0.687, valid_loss: 0.930, valid_acc: 0.637\n",
      "epoch:21, loss: 0.843, acc: 0.702, valid_loss: 0.829, valid_acc: 0.654\n",
      "epoch:22, loss: 0.808, acc: 0.713, valid_loss: 0.816, valid_acc: 0.657\n",
      "epoch:23, loss: 0.767, acc: 0.730, valid_loss: 0.767, valid_acc: 0.688\n",
      "epoch:24, loss: 0.724, acc: 0.743, valid_loss: 0.757, valid_acc: 0.677\n",
      "epoch:25, loss: 0.694, acc: 0.754, valid_loss: 0.709, valid_acc: 0.664\n",
      "epoch:26, loss: 0.655, acc: 0.769, valid_loss: 0.663, valid_acc: 0.689\n",
      "epoch:27, loss: 0.614, acc: 0.782, valid_loss: 0.659, valid_acc: 0.700\n",
      "epoch:28, loss: 0.605, acc: 0.784, valid_loss: 0.583, valid_acc: 0.707\n",
      "epoch:29, loss: 0.556, acc: 0.804, valid_loss: 0.547, valid_acc: 0.712\n",
      "epoch:30, loss: 0.504, acc: 0.821, valid_loss: 0.515, valid_acc: 0.726\n",
      "epoch:31, loss: 0.481, acc: 0.830, valid_loss: 0.541, valid_acc: 0.711\n",
      "epoch:32, loss: 0.450, acc: 0.842, valid_loss: 0.445, valid_acc: 0.721\n",
      "epoch:33, loss: 0.416, acc: 0.853, valid_loss: 0.416, valid_acc: 0.728\n",
      "epoch:34, loss: 0.383, acc: 0.866, valid_loss: 0.362, valid_acc: 0.708\n",
      "epoch:35, loss: 0.359, acc: 0.873, valid_loss: 0.377, valid_acc: 0.730\n",
      "epoch:36, loss: 0.332, acc: 0.882, valid_loss: 0.379, valid_acc: 0.742\n",
      "epoch:37, loss: 0.304, acc: 0.892, valid_loss: 0.351, valid_acc: 0.730\n",
      "epoch:38, loss: 0.285, acc: 0.899, valid_loss: 0.289, valid_acc: 0.735\n",
      "epoch:39, loss: 0.263, acc: 0.907, valid_loss: 0.278, valid_acc: 0.716\n",
      "epoch:40, loss: 0.248, acc: 0.911, valid_loss: 0.292, valid_acc: 0.742\n",
      "epoch:41, loss: 0.235, acc: 0.917, valid_loss: 0.251, valid_acc: 0.730\n",
      "epoch:42, loss: 0.222, acc: 0.921, valid_loss: 0.224, valid_acc: 0.736\n",
      "epoch:43, loss: 0.197, acc: 0.929, valid_loss: 0.230, valid_acc: 0.741\n",
      "epoch:44, loss: 0.191, acc: 0.932, valid_loss: 0.204, valid_acc: 0.744\n",
      "epoch:45, loss: 0.177, acc: 0.937, valid_loss: 0.224, valid_acc: 0.738\n",
      "epoch:46, loss: 0.169, acc: 0.941, valid_loss: 0.165, valid_acc: 0.738\n",
      "epoch:47, loss: 0.158, acc: 0.945, valid_loss: 0.179, valid_acc: 0.732\n",
      "epoch:48, loss: 0.160, acc: 0.944, valid_loss: 0.174, valid_acc: 0.733\n",
      "epoch:49, loss: 0.152, acc: 0.946, valid_loss: 0.146, valid_acc: 0.743\n",
      "epoch:50, loss: 0.136, acc: 0.952, valid_loss: 0.139, valid_acc: 0.739\n",
      "epoch:51, loss: 0.135, acc: 0.952, valid_loss: 0.145, valid_acc: 0.746\n",
      "epoch:52, loss: 0.126, acc: 0.955, valid_loss: 0.128, valid_acc: 0.719\n",
      "epoch:53, loss: 0.119, acc: 0.957, valid_loss: 0.107, valid_acc: 0.739\n",
      "epoch:54, loss: 0.117, acc: 0.959, valid_loss: 0.158, valid_acc: 0.744\n",
      "epoch:55, loss: 0.115, acc: 0.960, valid_loss: 0.116, valid_acc: 0.741\n",
      "epoch:56, loss: 0.104, acc: 0.964, valid_loss: 0.109, valid_acc: 0.751\n",
      "epoch:57, loss: 0.109, acc: 0.962, valid_loss: 0.111, valid_acc: 0.737\n",
      "epoch:58, loss: 0.106, acc: 0.962, valid_loss: 0.125, valid_acc: 0.749\n",
      "epoch:59, loss: 0.097, acc: 0.965, valid_loss: 0.082, valid_acc: 0.734\n",
      "epoch:60, loss: 0.102, acc: 0.965, valid_loss: 0.113, valid_acc: 0.745\n",
      "epoch:61, loss: 0.094, acc: 0.967, valid_loss: 0.114, valid_acc: 0.745\n",
      "epoch:62, loss: 0.086, acc: 0.971, valid_loss: 0.097, valid_acc: 0.739\n",
      "epoch:63, loss: 0.086, acc: 0.969, valid_loss: 0.089, valid_acc: 0.745\n",
      "epoch:64, loss: 0.087, acc: 0.971, valid_loss: 0.068, valid_acc: 0.730\n",
      "epoch:65, loss: 0.092, acc: 0.967, valid_loss: 0.087, valid_acc: 0.743\n",
      "epoch:66, loss: 0.079, acc: 0.972, valid_loss: 0.084, valid_acc: 0.745\n",
      "epoch:67, loss: 0.085, acc: 0.971, valid_loss: 0.096, valid_acc: 0.736\n",
      "epoch:68, loss: 0.077, acc: 0.973, valid_loss: 0.090, valid_acc: 0.743\n",
      "epoch:69, loss: 0.079, acc: 0.972, valid_loss: 0.082, valid_acc: 0.740\n",
      "epoch:70, loss: 0.079, acc: 0.972, valid_loss: 0.063, valid_acc: 0.743\n",
      "epoch:71, loss: 0.069, acc: 0.976, valid_loss: 0.074, valid_acc: 0.748\n",
      "epoch:72, loss: 0.070, acc: 0.976, valid_loss: 0.076, valid_acc: 0.739\n",
      "epoch:73, loss: 0.071, acc: 0.976, valid_loss: 0.083, valid_acc: 0.726\n",
      "epoch:74, loss: 0.068, acc: 0.976, valid_loss: 0.072, valid_acc: 0.743\n",
      "epoch:75, loss: 0.067, acc: 0.977, valid_loss: 0.059, valid_acc: 0.751\n",
      "epoch:76, loss: 0.067, acc: 0.977, valid_loss: 0.065, valid_acc: 0.754\n",
      "epoch:77, loss: 0.073, acc: 0.975, valid_loss: 0.072, valid_acc: 0.748\n",
      "epoch:78, loss: 0.062, acc: 0.978, valid_loss: 0.073, valid_acc: 0.745\n",
      "epoch:79, loss: 0.063, acc: 0.978, valid_loss: 0.046, valid_acc: 0.746\n",
      "epoch:80, loss: 0.063, acc: 0.979, valid_loss: 0.055, valid_acc: 0.740\n",
      "epoch:81, loss: 0.065, acc: 0.978, valid_loss: 0.077, valid_acc: 0.749\n",
      "epoch:82, loss: 0.061, acc: 0.979, valid_loss: 0.046, valid_acc: 0.756\n",
      "epoch:83, loss: 0.059, acc: 0.979, valid_loss: 0.092, valid_acc: 0.756\n",
      "epoch:84, loss: 0.059, acc: 0.979, valid_loss: 0.061, valid_acc: 0.754\n",
      "epoch:85, loss: 0.063, acc: 0.979, valid_loss: 0.054, valid_acc: 0.747\n",
      "epoch:86, loss: 0.058, acc: 0.980, valid_loss: 0.080, valid_acc: 0.746\n",
      "epoch:87, loss: 0.063, acc: 0.978, valid_loss: 0.064, valid_acc: 0.754\n",
      "epoch:88, loss: 0.062, acc: 0.978, valid_loss: 0.050, valid_acc: 0.752\n",
      "epoch:89, loss: 0.057, acc: 0.980, valid_loss: 0.071, valid_acc: 0.715\n",
      "epoch:90, loss: 0.058, acc: 0.979, valid_loss: 0.058, valid_acc: 0.755\n",
      "epoch:91, loss: 0.055, acc: 0.981, valid_loss: 0.051, valid_acc: 0.750\n",
      "epoch:92, loss: 0.054, acc: 0.981, valid_loss: 0.068, valid_acc: 0.755\n",
      "epoch:93, loss: 0.052, acc: 0.982, valid_loss: 0.060, valid_acc: 0.748\n",
      "epoch:94, loss: 0.055, acc: 0.981, valid_loss: 0.071, valid_acc: 0.746\n",
      "epoch:95, loss: 0.050, acc: 0.982, valid_loss: 0.051, valid_acc: 0.752\n",
      "epoch:96, loss: 0.056, acc: 0.980, valid_loss: 0.061, valid_acc: 0.747\n",
      "epoch:97, loss: 0.057, acc: 0.980, valid_loss: 0.066, valid_acc: 0.726\n",
      "epoch:98, loss: 0.054, acc: 0.982, valid_loss: 0.081, valid_acc: 0.748\n",
      "epoch:99, loss: 0.048, acc: 0.983, valid_loss: 0.036, valid_acc: 0.758\n",
      "Training completed in 6.8307398398717245min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "since = time.time()\n",
    "key = random.PRNGKey(0)\n",
    "key, *dropout_key = random.split(key,n_devices+1)\n",
    "dropout_key = jnp.stack(dropout_key)\n",
    "\n",
    "    \n",
    "for i in range(EPOCHS):\n",
    "    train_data_gen = data_generator(x_train_normalized,\n",
    "                            y_train_ohe,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            is_valid=False,\n",
    "                            key=key\n",
    "                           )\n",
    "    valid_data_gen = data_generator(x_valid_normalized,\n",
    "                               y_valid_ohe,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               is_valid=True\n",
    "                               )\n",
    "    # train\n",
    "    train_batch_loss = 0\n",
    "    train_batch_metric = 0\n",
    "    for step in range(num_train_batches):\n",
    "        x,y = next(train_data_gen)\n",
    "        x,y = psplit(x),psplit(y)\n",
    "        combined_states,opt_states,dropout_key,l,metric = train_one_step2(x,y,combined_states,opt_states,dropout_key)\n",
    "        train_batch_loss += l\n",
    "        train_batch_metric += metric\n",
    "    train_batch_loss/=num_train_batches\n",
    "    train_batch_metric/=num_train_batches\n",
    "    \n",
    "    # eval\n",
    "    eval_batch_loss = 0\n",
    "    eval_batch_metric = 0\n",
    "    for step in range(num_valid_batches):\n",
    "        x,y = next(valid_data_gen)\n",
    "        loss, metric = eval_one_step(x,y,combined_states)\n",
    "        eval_batch_loss += l\n",
    "        eval_batch_metric += metric\n",
    "    eval_batch_loss/=num_valid_batches\n",
    "    eval_batch_metric/=num_valid_batches\n",
    "    \n",
    "    print(f\"epoch:{i}, loss: {train_batch_loss:.3f}, acc: {train_batch_metric:.3f}, valid_loss: {eval_batch_loss:.3f}, valid_acc: {eval_batch_metric:.3f}\")\n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {}min'.format(time_elapsed/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
