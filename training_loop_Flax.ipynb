{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.040794,"end_time":"2022-01-04T19:06:57.340525","exception":false,"start_time":"2022-01-04T19:06:57.299731","status":"completed"},"tags":[]},"source":["Modified based on https://www.kaggle.com/code/aakashnain/building-models-in-jax-part2-flax#Evaluation\n","\n","Showcase:\n","1. Train model with BatchNorm and Dropout (how to track/update states for BN and how to update key for dropout)\n","2. Train_one_step & eval_one_step\n","3. How to change between Training and Eval mode"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:51:49.527320Z","iopub.status.busy":"2023-07-11T16:51:49.526581Z","iopub.status.idle":"2023-07-11T16:51:49.559731Z","shell.execute_reply":"2023-07-11T16:51:49.558856Z","shell.execute_reply.started":"2023-07-11T16:51:49.527224Z"},"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-11T16:53:42.356175Z","iopub.status.busy":"2023-07-11T16:53:42.355854Z","iopub.status.idle":"2023-07-11T16:53:50.661530Z","shell.execute_reply":"2023-07-11T16:53:50.660627Z","shell.execute_reply.started":"2023-07-11T16:53:42.356139Z"},"papermill":{"duration":7.602287,"end_time":"2022-01-04T19:07:04.983064","exception":false,"start_time":"2022-01-04T19:06:57.380777","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.datasets import cifar10\n","from flax.core import freeze, unfreeze\n","import jax\n","import jax.numpy as jnp\n","from jax import random\n","from jax import make_jaxpr\n","from jax.config import config\n","from jax import value_and_grad\n","from jax import grad, vmap, pmap, jit\n","\n","import optax\n","from flax import linen as nn\n","from flax.training import train_state\n","\n","np.random.seed(1234)\n","%config IPCompleter.use_jedi = False"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.022962,"end_time":"2022-01-04T19:07:05.029004","exception":false,"start_time":"2022-01-04T19:07:05.006042","status":"completed"},"tags":[]},"source":["# Dataset\n","\n","We will use the Cifar-10 dataset for this experiment. You can download it or add it from Kaggle as well, but I am directly importing it from the available `tf.keras.datasets` for the sake of simplicity and brevity"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:54:08.284072Z","iopub.status.busy":"2023-07-11T16:54:08.283736Z","iopub.status.idle":"2023-07-11T16:54:21.895655Z","shell.execute_reply":"2023-07-11T16:54:21.894706Z","shell.execute_reply.started":"2023-07-11T16:54:08.284036Z"},"papermill":{"duration":9.318512,"end_time":"2022-01-04T19:07:14.370367","exception":false,"start_time":"2022-01-04T19:07:05.051855","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of training samples: 50000 with samples shape: (32, 32, 3)\n","Number of validation samples: 10000 with samples shape: (32, 32, 3)\n"]}],"source":["# The downloaded dataset consists of two tuples. The first\n","# tuple represents the training data consisting of pairs of images\n","# and labels. Similary, the second tuple consists of validation/test data.\n","# I will use the second tuple as the validation data for this demo\n","\n","(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\n","print(f\"\\nNumber of training samples: {len(x_train)} with samples shape: {x_train.shape[1:]}\")\n","print(f\"Number of validation samples: {len(x_valid)} with samples shape: {x_valid.shape[1:]}\")\n","\n","\n","# There are 10 classes in this dataset. We will create a dictionary for\n","# mapping the names of the classes represented by the integer labels\n","# Labels dictionary\n","labels_dict = {\n","    0: \"airplane\",\n","    1: \"automobile\",\n","    2: \"bird\",\n","    3: \"cat\",\n","    4: \"deer\",\n","    5: \"dog\",\n","    6: \"frog\",\n","    7: \"horse\",\n","    8: \"ship\",\n","    9: \"truck\"\n","}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.061566,"end_time":"2022-01-04T19:07:21.850018","exception":false,"start_time":"2022-01-04T19:07:21.788452","status":"completed"},"tags":[]},"source":["Perfect! The augmentation pipeline is working as expected. Let's move to the next step.\n","\n","# Data Preprocessing\n","\n","For data preprocessing, we will apply these two things:\n","1. We will normalize the image data so that the pixel values for each image is in the range `[0, 1]`\n","2. We will one-hot encode our labels"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:04.09014Z","iopub.status.busy":"2022-02-13T17:08:04.089306Z","iopub.status.idle":"2022-02-13T17:08:05.791843Z","shell.execute_reply":"2022-02-13T17:08:05.791083Z","shell.execute_reply.started":"2022-02-13T17:08:04.090101Z"},"papermill":{"duration":2.688759,"end_time":"2022-01-04T19:07:24.600434","exception":false,"start_time":"2022-01-04T19:07:21.911675","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images shape:   (50000, 32, 32, 3)  Labels shape: (50000, 10)\n","Validation images shape: (10000, 32, 32, 3)  Labels shape: (10000, 10)\n"]}],"source":["# Normalize the image pixels in the range [0, 1]\n","x_train_normalized = jnp.array(x_train / 255.)\n","x_valid_normalized = jnp.array(x_valid / 255.)\n","\n","# One hot encoding applied to the labels. We have 10\n","# classes in the dataset, hence the depth of OHE would be 10\n","y_train_ohe = jnp.squeeze(jax.nn.one_hot(y_train, num_classes=10))\n","y_valid_ohe = jnp.squeeze(jax.nn.one_hot(y_valid, num_classes=10))\n","\n","print(f\"Training images shape:   {x_train_normalized.shape}  Labels shape: {y_train_ohe.shape}\")\n","print(f\"Validation images shape: {x_valid_normalized.shape}  Labels shape: {y_valid_ohe.shape}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.060709,"end_time":"2022-01-04T19:07:24.724781","exception":false,"start_time":"2022-01-04T19:07:24.664072","status":"completed"},"tags":[]},"source":["# Data Generator\n","\n","Now that we have preprocessed our dataset, we need to define our data generator that will stream batches of data, where each batch is a pair of images and the corresponding labels. We will apply data augmentation to the training data only."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:06.163836Z","iopub.status.busy":"2022-02-13T17:08:06.163471Z","iopub.status.idle":"2022-02-13T17:08:06.990355Z","shell.execute_reply":"2022-02-13T17:08:06.988483Z","shell.execute_reply.started":"2022-02-13T17:08:06.163783Z"},"papermill":{"duration":1.068589,"end_time":"2022-01-04T19:07:25.852618","exception":false,"start_time":"2022-01-04T19:07:24.784029","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def identity(img):\n","    \"\"\"Returns an image as it is.\"\"\"\n","    return img\n","\n","\n","def flip_left_right(img):\n","    \"\"\"Flips an image left/right direction.\"\"\"\n","    return jnp.fliplr(img)\n","\n","\n","def random_horizontal_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_left_right, identity, img)\n","    \n","\n","\n","\n","# All the above function are written to work on a single example. \n","# We will use `vmap` to get a version of these functions that can\n","# operate on a batch of images. We will also add the `jit` transformation\n","# on top of it so that the whole pipeline can be compiled and executed faster\n","random_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\n","\n","\n","@jax.jit\n","def augment_images(images, key):\n","    \"\"\"Augment a batch of input images.\n","    \n","    Args:\n","        images: Batch of input images as a jax array\n","        key: Seed/Key for random functions for generating booleans\n","    Returns:\n","        Augmented images with the same shape as the input images\n","    \"\"\"\n","    \n","    batch_size = len(images)\n","    \n","    # 2. Flip horizontally\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_horizontal_flip_jitted(images, flip)\n","    return augmented"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch of images is of shape:  (8, 32, 32, 3)\n","Batch of labels is of shape:  (8, 10)\n"]}],"source":["def data_generator(images, labels, batch_size=128, is_valid=False, key=None):\n","    \"\"\"Generates batches of data from a given dataset.\n","    \n","    Args:\n","        images: Image data represented by a ndarray\n","        labels: One-hot enocded labels\n","        batch_size: Number of data points in a single batch\n","        is_valid: (Boolean) If validation data, then don't shuffle and\n","                    don't apply any augmentation\n","        key: PRNG key needed for augmentation\n","    Yields:\n","        Batches of images-labels pairs\n","    \"\"\"\n","    \n","    # 1. Calculate the total number of batches\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    \n","    # 2. Get the indices and shuffle them\n","    indices = np.arange(len(images))\n","    \n","    if not is_valid:\n","        if key is None:\n","             raise ValueError(\"A PRNG key is required if `aug` is set to True\")\n","        else:\n","            np.random.shuffle(indices)\n","    \n","    for batch in range(num_batches):\n","        curr_idx = indices[batch * batch_size: (batch+1) * batch_size]\n","        batch_images = images[curr_idx]\n","        batch_labels = labels[curr_idx]\n","        \n","        if not is_valid: \n","            batch_images = augment_images(batch_images, key=key)\n","        yield batch_images, batch_labels\n","        \n","        \n","\n","# Sanity Check: To make sure that the batches generated by the data\n","# generator are of correct size, we will just pull a batch of data and\n","# will check the shape of the images and the labels\n","\n","sample_data_gen = data_generator(\n","    images=x_train_normalized,\n","    labels=y_train_ohe,\n","    batch_size=8,\n","    is_valid=False,\n","    key=random.PRNGKey(0)\n",")\n","\n","sample_batch_images, sample_batch_labels = next(sample_data_gen)\n","print(\"Batch of images is of shape: \", sample_batch_images.shape)\n","print(\"Batch of labels is of shape: \", sample_batch_labels.shape)\n","\n","# Clean up unnecessary objects\n","del sample_data_gen, sample_batch_images, sample_batch_labels"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.059208,"end_time":"2022-01-04T19:07:25.972317","exception":false,"start_time":"2022-01-04T19:07:25.913109","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from typing import Any\n","\n","\n","class resNet(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = inputs\n","        x = nn.Conv(x.shape[-1], (3, 3), padding=\"SAME\",use_bias=False)(x)\n","        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        x = nn.gelu(x)\n","        return inputs + x\n","\n","class Pool(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = nn.Conv(inputs.shape[-1]*4, (3, 3), (2, 2), padding=\"SAME\",use_bias=False)(inputs)\n","        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        x = nn.gelu(x)\n","        return x\n","    \n","class CifarCNN(nn.Module):\n","    \"\"\"CIFAR-10 Classifier\"\"\"\n","    res_repeats: int = 3\n","    out_repeats: int = 4\n","    @nn.compact\n","    def __call__(self, x, IsTrain):\n","        x = Pool()(x,IsTrain)\n","        for _ in range(self.out_repeats):\n","            x = Pool()(x,IsTrain)\n","            for _ in range(self.res_repeats):\n","                x = resNet()(x,IsTrain)\n","        # Flatten \n","        x = x.reshape(x.shape[0], -1)\n","        # Dense layers\n","        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        # We are going to return the logits and not\n","        # the softamx activations \n","        x = nn.Dense(10)(x)\n","        return x\n","\n","EPOCHS = 100\n","BATCH_SIZE = 128\n","num_train_batches = len(x_train) // BATCH_SIZE\n","num_valid_batches = len(x_valid) // BATCH_SIZE\n","total_steps = EPOCHS * num_train_batches\n","\n","model = CifarCNN()\n","params = model.init({'params':random.PRNGKey(2),'dropout':random.PRNGKey(3)},jnp.ones([1, 32, 32, 3]),True)\n","states,params = params.pop('params')\n","# _scheduler = optax.piecewise_constant_schedule(init_value=1e-2,\n","#                                                boundaries_and_scales={int(total_steps*0.6):0.25,\n","#                                                                       int(total_steps*0.85):0.25})\n","opt = optax.adamw(learning_rate=1e-2)\n","opt_states = opt.init(params)\n","combined_states = freeze({'params':params,**states})\n","\n","@jax.jit\n","def train_one_step(x,y,combined_states,opt_states,dropout_key):\n","    return_key,dropout_key = random.split(dropout_key,2)\n","    states,params = combined_states.pop('params')\n","    def loss_fn(params):\n","        yhat,new_states = model.apply({'params':params,**states},x,True,\\\n","                                   mutable='batch_stats',rngs={'dropout':dropout_key})\n","        loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","        metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","        return loss,(new_states,metric)\n","    grad_fn = jax.value_and_grad(loss_fn,has_aux=True)\n","    (l,(states,metric)),grads = grad_fn(params)\n","    updates, opt_states = opt.update(grads, opt_states,params=params)\n","    params = optax.apply_updates(params, updates)\n","    combined_states = freeze({'params':params,**states})\n","    return combined_states,opt_states,return_key,l,metric\n","\n","@jax.jit\n","def eval_one_step(x,y,combined_states):\n","    yhat = model.apply(combined_states,x,False)\n","    loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","    metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","    return loss, metric"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","We have coded every piece required for training and evaluation. We will now define our training loop. "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:07.907825Z","iopub.status.busy":"2022-02-13T17:08:07.907072Z","iopub.status.idle":"2022-02-13T17:11:01.365961Z","shell.execute_reply":"2022-02-13T17:11:01.365104Z","shell.execute_reply.started":"2022-02-13T17:08:07.90777Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:0, loss: 3.000, acc: 0.221, valid_loss: 2.047, valid_acc: 0.196\n","epoch:1, loss: 2.085, acc: 0.347, valid_loss: 1.629, valid_acc: 0.340\n","epoch:2, loss: 1.579, acc: 0.446, valid_loss: 1.591, valid_acc: 0.442\n","epoch:3, loss: 1.357, acc: 0.514, valid_loss: 1.391, valid_acc: 0.523\n","epoch:4, loss: 1.197, acc: 0.571, valid_loss: 1.070, valid_acc: 0.562\n","epoch:5, loss: 1.090, acc: 0.612, valid_loss: 1.017, valid_acc: 0.611\n","epoch:6, loss: 0.984, acc: 0.652, valid_loss: 0.999, valid_acc: 0.613\n","epoch:7, loss: 0.905, acc: 0.679, valid_loss: 0.861, valid_acc: 0.653\n","epoch:8, loss: 0.840, acc: 0.704, valid_loss: 0.868, valid_acc: 0.647\n","epoch:9, loss: 0.771, acc: 0.729, valid_loss: 0.913, valid_acc: 0.686\n","epoch:10, loss: 0.715, acc: 0.751, valid_loss: 0.776, valid_acc: 0.707\n","epoch:11, loss: 0.654, acc: 0.772, valid_loss: 0.539, valid_acc: 0.639\n","epoch:12, loss: 0.610, acc: 0.786, valid_loss: 0.613, valid_acc: 0.721\n","epoch:13, loss: 0.558, acc: 0.804, valid_loss: 0.672, valid_acc: 0.743\n","epoch:14, loss: 0.508, acc: 0.823, valid_loss: 0.452, valid_acc: 0.732\n","epoch:15, loss: 0.461, acc: 0.838, valid_loss: 0.411, valid_acc: 0.744\n","epoch:16, loss: 0.417, acc: 0.855, valid_loss: 0.433, valid_acc: 0.734\n","epoch:17, loss: 0.389, acc: 0.866, valid_loss: 0.390, valid_acc: 0.745\n","epoch:18, loss: 0.349, acc: 0.879, valid_loss: 0.313, valid_acc: 0.736\n","epoch:19, loss: 0.323, acc: 0.889, valid_loss: 0.323, valid_acc: 0.755\n","epoch:20, loss: 0.296, acc: 0.898, valid_loss: 0.391, valid_acc: 0.747\n","epoch:21, loss: 0.276, acc: 0.904, valid_loss: 0.212, valid_acc: 0.745\n","epoch:22, loss: 0.282, acc: 0.903, valid_loss: 0.308, valid_acc: 0.730\n","epoch:23, loss: 0.382, acc: 0.877, valid_loss: 0.415, valid_acc: 0.688\n","epoch:24, loss: 0.258, acc: 0.912, valid_loss: 0.231, valid_acc: 0.741\n","epoch:25, loss: 0.196, acc: 0.933, valid_loss: 0.167, valid_acc: 0.709\n","epoch:26, loss: 0.184, acc: 0.935, valid_loss: 0.188, valid_acc: 0.754\n","epoch:27, loss: 0.172, acc: 0.941, valid_loss: 0.170, valid_acc: 0.760\n","epoch:28, loss: 0.175, acc: 0.941, valid_loss: 0.138, valid_acc: 0.760\n","epoch:29, loss: 0.172, acc: 0.941, valid_loss: 0.104, valid_acc: 0.752\n","epoch:30, loss: 0.167, acc: 0.943, valid_loss: 0.255, valid_acc: 0.761\n","epoch:31, loss: 0.163, acc: 0.945, valid_loss: 0.148, valid_acc: 0.755\n","epoch:32, loss: 0.149, acc: 0.949, valid_loss: 0.137, valid_acc: 0.765\n","epoch:33, loss: 0.164, acc: 0.945, valid_loss: 0.228, valid_acc: 0.730\n","epoch:34, loss: 0.391, acc: 0.885, valid_loss: 0.197, valid_acc: 0.767\n","epoch:35, loss: 0.152, acc: 0.948, valid_loss: 0.112, valid_acc: 0.774\n","epoch:36, loss: 0.118, acc: 0.960, valid_loss: 0.143, valid_acc: 0.775\n","epoch:37, loss: 0.112, acc: 0.962, valid_loss: 0.197, valid_acc: 0.755\n","epoch:38, loss: 0.117, acc: 0.960, valid_loss: 0.187, valid_acc: 0.761\n","epoch:39, loss: 0.124, acc: 0.958, valid_loss: 0.151, valid_acc: 0.759\n","epoch:40, loss: 0.115, acc: 0.961, valid_loss: 0.060, valid_acc: 0.748\n","epoch:41, loss: 0.128, acc: 0.957, valid_loss: 0.072, valid_acc: 0.751\n","epoch:42, loss: 0.118, acc: 0.960, valid_loss: 0.082, valid_acc: 0.732\n","epoch:43, loss: 0.139, acc: 0.955, valid_loss: 0.235, valid_acc: 0.757\n","epoch:44, loss: 0.169, acc: 0.946, valid_loss: 0.062, valid_acc: 0.752\n","epoch:45, loss: 0.185, acc: 0.943, valid_loss: 0.088, valid_acc: 0.759\n","epoch:46, loss: 0.379, acc: 0.900, valid_loss: 0.235, valid_acc: 0.746\n","epoch:47, loss: 0.171, acc: 0.945, valid_loss: 0.125, valid_acc: 0.771\n","epoch:48, loss: 0.103, acc: 0.966, valid_loss: 0.068, valid_acc: 0.770\n","epoch:49, loss: 0.082, acc: 0.972, valid_loss: 0.045, valid_acc: 0.777\n","epoch:50, loss: 0.077, acc: 0.974, valid_loss: 0.122, valid_acc: 0.768\n","epoch:51, loss: 0.078, acc: 0.973, valid_loss: 0.050, valid_acc: 0.774\n","epoch:52, loss: 0.094, acc: 0.969, valid_loss: 0.169, valid_acc: 0.761\n","epoch:53, loss: 0.093, acc: 0.969, valid_loss: 0.114, valid_acc: 0.759\n","epoch:54, loss: 0.106, acc: 0.965, valid_loss: 0.094, valid_acc: 0.747\n","epoch:55, loss: 0.112, acc: 0.963, valid_loss: 0.042, valid_acc: 0.738\n","epoch:56, loss: 0.101, acc: 0.967, valid_loss: 0.133, valid_acc: 0.775\n","epoch:57, loss: 0.092, acc: 0.971, valid_loss: 0.217, valid_acc: 0.766\n","epoch:58, loss: 0.096, acc: 0.968, valid_loss: 0.078, valid_acc: 0.768\n","epoch:59, loss: 0.104, acc: 0.967, valid_loss: 0.062, valid_acc: 0.770\n","epoch:60, loss: 0.362, acc: 0.916, valid_loss: 0.293, valid_acc: 0.735\n","epoch:61, loss: 0.318, acc: 0.906, valid_loss: 0.159, valid_acc: 0.767\n","epoch:62, loss: 0.100, acc: 0.966, valid_loss: 0.088, valid_acc: 0.779\n","epoch:63, loss: 0.069, acc: 0.976, valid_loss: 0.052, valid_acc: 0.773\n","epoch:64, loss: 0.067, acc: 0.977, valid_loss: 0.041, valid_acc: 0.783\n","epoch:65, loss: 0.065, acc: 0.979, valid_loss: 0.095, valid_acc: 0.777\n","epoch:66, loss: 0.067, acc: 0.978, valid_loss: 0.050, valid_acc: 0.770\n","epoch:67, loss: 0.070, acc: 0.977, valid_loss: 0.036, valid_acc: 0.770\n","epoch:68, loss: 0.081, acc: 0.973, valid_loss: 0.046, valid_acc: 0.758\n","epoch:69, loss: 0.089, acc: 0.971, valid_loss: 0.057, valid_acc: 0.766\n","epoch:70, loss: 0.078, acc: 0.974, valid_loss: 0.068, valid_acc: 0.768\n","epoch:71, loss: 0.080, acc: 0.973, valid_loss: 0.103, valid_acc: 0.757\n","epoch:72, loss: 0.097, acc: 0.970, valid_loss: 0.069, valid_acc: 0.751\n","epoch:73, loss: 0.085, acc: 0.972, valid_loss: 0.072, valid_acc: 0.776\n","epoch:74, loss: 0.085, acc: 0.974, valid_loss: 0.105, valid_acc: 0.753\n","epoch:75, loss: 0.090, acc: 0.972, valid_loss: 0.112, valid_acc: 0.748\n","epoch:76, loss: 0.095, acc: 0.971, valid_loss: 0.081, valid_acc: 0.763\n","epoch:77, loss: 0.272, acc: 0.938, valid_loss: 0.693, valid_acc: 0.643\n","epoch:78, loss: 0.200, acc: 0.945, valid_loss: 0.062, valid_acc: 0.766\n","epoch:79, loss: 0.185, acc: 0.946, valid_loss: 0.065, valid_acc: 0.772\n","epoch:80, loss: 0.070, acc: 0.976, valid_loss: 0.070, valid_acc: 0.781\n","epoch:81, loss: 0.057, acc: 0.982, valid_loss: 0.024, valid_acc: 0.778\n","epoch:82, loss: 0.052, acc: 0.983, valid_loss: 0.029, valid_acc: 0.771\n","epoch:83, loss: 0.056, acc: 0.982, valid_loss: 0.014, valid_acc: 0.779\n","epoch:84, loss: 0.059, acc: 0.980, valid_loss: 0.044, valid_acc: 0.769\n","epoch:85, loss: 0.068, acc: 0.978, valid_loss: 0.082, valid_acc: 0.764\n","epoch:86, loss: 0.065, acc: 0.979, valid_loss: 0.065, valid_acc: 0.770\n","epoch:87, loss: 0.066, acc: 0.979, valid_loss: 0.025, valid_acc: 0.761\n","epoch:88, loss: 0.077, acc: 0.976, valid_loss: 0.003, valid_acc: 0.748\n","epoch:89, loss: 0.076, acc: 0.977, valid_loss: 0.063, valid_acc: 0.771\n","epoch:90, loss: 0.071, acc: 0.977, valid_loss: 0.106, valid_acc: 0.763\n","epoch:91, loss: 0.073, acc: 0.977, valid_loss: 0.107, valid_acc: 0.777\n","epoch:92, loss: 0.077, acc: 0.976, valid_loss: 0.021, valid_acc: 0.746\n","epoch:93, loss: 0.125, acc: 0.965, valid_loss: 0.230, valid_acc: 0.755\n","epoch:94, loss: 0.123, acc: 0.966, valid_loss: 0.055, valid_acc: 0.758\n","epoch:95, loss: 0.075, acc: 0.978, valid_loss: 0.085, valid_acc: 0.765\n","epoch:96, loss: 0.058, acc: 0.982, valid_loss: 0.075, valid_acc: 0.783\n","epoch:97, loss: 0.058, acc: 0.981, valid_loss: 0.060, valid_acc: 0.770\n","epoch:98, loss: 0.059, acc: 0.981, valid_loss: 0.177, valid_acc: 0.769\n","epoch:99, loss: 0.081, acc: 0.975, valid_loss: 0.033, valid_acc: 0.748\n"]}],"source":["key = random.PRNGKey(0)\n","key, dropout_key = random.split(key)\n","\n","    \n","for i in range(EPOCHS):\n","    train_data_gen = data_generator(x_train_normalized,\n","                            y_train_ohe,\n","                            batch_size=BATCH_SIZE,\n","                            is_valid=False,\n","                            key=key\n","                           )\n","    valid_data_gen = data_generator(x_valid_normalized,\n","                               y_valid_ohe,\n","                               batch_size=BATCH_SIZE,\n","                               is_valid=True\n","                               )\n","    # train\n","    train_batch_loss = 0\n","    train_batch_metric = 0\n","    for step in range(num_train_batches):\n","        x,y = next(train_data_gen)\n","        combined_states,opt_states,dropout_key,l,metric = train_one_step(x,y,combined_states,opt_states,dropout_key)\n","        train_batch_loss += l\n","        train_batch_metric += metric\n","    train_batch_loss/=num_train_batches\n","    train_batch_metric/=num_train_batches\n","    \n","    # eval\n","    eval_batch_loss = 0\n","    eval_batch_metric = 0\n","    for step in range(num_valid_batches):\n","        x,y = next(valid_data_gen)\n","        loss, metric = eval_one_step(x,y,combined_states)\n","        eval_batch_loss += l\n","        eval_batch_metric += metric\n","    eval_batch_loss/=num_valid_batches\n","    eval_batch_metric/=num_valid_batches\n","    \n","    print(f\"epoch:{i}, loss: {train_batch_loss:.3f}, acc: {train_batch_metric:.3f}, valid_loss: {eval_batch_loss:.3f}, valid_acc: {eval_batch_metric:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
