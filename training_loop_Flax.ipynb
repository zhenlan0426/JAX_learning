{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.040794,"end_time":"2022-01-04T19:06:57.340525","exception":false,"start_time":"2022-01-04T19:06:57.299731","status":"completed"},"tags":[]},"source":["Modified based on https://www.kaggle.com/code/aakashnain/building-models-in-jax-part2-flax#Evaluation"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:51:49.527320Z","iopub.status.busy":"2023-07-11T16:51:49.526581Z","iopub.status.idle":"2023-07-11T16:51:49.559731Z","shell.execute_reply":"2023-07-11T16:51:49.558856Z","shell.execute_reply.started":"2023-07-11T16:51:49.527224Z"},"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-11T16:53:42.356175Z","iopub.status.busy":"2023-07-11T16:53:42.355854Z","iopub.status.idle":"2023-07-11T16:53:50.661530Z","shell.execute_reply":"2023-07-11T16:53:50.660627Z","shell.execute_reply.started":"2023-07-11T16:53:42.356139Z"},"papermill":{"duration":7.602287,"end_time":"2022-01-04T19:07:04.983064","exception":false,"start_time":"2022-01-04T19:06:57.380777","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.datasets import cifar10\n","from flax.core import freeze, unfreeze\n","import jax\n","import jax.numpy as jnp\n","from jax import random\n","from jax import make_jaxpr\n","from jax.config import config\n","from jax import value_and_grad\n","from jax import grad, vmap, pmap, jit\n","\n","import optax\n","from flax import linen as nn\n","from flax.training import train_state\n","\n","np.random.seed(1234)\n","%config IPCompleter.use_jedi = False"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.022962,"end_time":"2022-01-04T19:07:05.029004","exception":false,"start_time":"2022-01-04T19:07:05.006042","status":"completed"},"tags":[]},"source":["# Dataset\n","\n","We will use the Cifar-10 dataset for this experiment. You can download it or add it from Kaggle as well, but I am directly importing it from the available `tf.keras.datasets` for the sake of simplicity and brevity"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:54:08.284072Z","iopub.status.busy":"2023-07-11T16:54:08.283736Z","iopub.status.idle":"2023-07-11T16:54:21.895655Z","shell.execute_reply":"2023-07-11T16:54:21.894706Z","shell.execute_reply.started":"2023-07-11T16:54:08.284036Z"},"papermill":{"duration":9.318512,"end_time":"2022-01-04T19:07:14.370367","exception":false,"start_time":"2022-01-04T19:07:05.051855","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of training samples: 50000 with samples shape: (32, 32, 3)\n","Number of validation samples: 10000 with samples shape: (32, 32, 3)\n"]}],"source":["# The downloaded dataset consists of two tuples. The first\n","# tuple represents the training data consisting of pairs of images\n","# and labels. Similary, the second tuple consists of validation/test data.\n","# I will use the second tuple as the validation data for this demo\n","\n","(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\n","print(f\"\\nNumber of training samples: {len(x_train)} with samples shape: {x_train.shape[1:]}\")\n","print(f\"Number of validation samples: {len(x_valid)} with samples shape: {x_valid.shape[1:]}\")\n","\n","\n","# There are 10 classes in this dataset. We will create a dictionary for\n","# mapping the names of the classes represented by the integer labels\n","# Labels dictionary\n","labels_dict = {\n","    0: \"airplane\",\n","    1: \"automobile\",\n","    2: \"bird\",\n","    3: \"cat\",\n","    4: \"deer\",\n","    5: \"dog\",\n","    6: \"frog\",\n","    7: \"horse\",\n","    8: \"ship\",\n","    9: \"truck\"\n","}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.055043,"end_time":"2022-01-04T19:07:15.683699","exception":false,"start_time":"2022-01-04T19:07:15.628656","status":"completed"},"tags":[]},"source":["# Data Augmentation\n","\n","We will apply image augmentation, and that too, purely in JAX. For augmentation, we will be using three different augmentation techniques:\n","1. Random rotation by 90 degrees\n","2. Random horizontal flips\n","3. Random vertical flips\n","\n","For each of these augmentations:\n","1. We will define a function that will either return an augmented image or an identity image\n","2. Use [**vmap**](https://www.kaggle.com/aakashnain/tf-jax-tutorials-part-8-vmap-pmap#Data-Augmentation---Building-a-simple,-fast,-and-scalable-pipeline) to do augmentation in batches\n","3. [**jit**](https://www.kaggle.com/aakashnain/tf-jax-tutorials-part-7-jit-in-jax) the whole augmentation pipeline"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:07:57.857213Z","iopub.status.busy":"2022-02-13T17:07:57.856965Z","iopub.status.idle":"2022-02-13T17:07:57.871954Z","shell.execute_reply":"2022-02-13T17:07:57.87131Z","shell.execute_reply.started":"2022-02-13T17:07:57.857176Z"},"papermill":{"duration":0.269247,"end_time":"2022-01-04T19:07:16.006937","exception":false,"start_time":"2022-01-04T19:07:15.73769","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def rotate_90(img):\n","    \"\"\"Rotates an image by 90 degress k times.\"\"\"\n","    return jnp.rot90(img, k=1, axes=(0, 1))\n","\n","\n","def identity(img):\n","    \"\"\"Returns an image as it is.\"\"\"\n","    return img\n","\n","\n","def flip_left_right(img):\n","    \"\"\"Flips an image left/right direction.\"\"\"\n","    return jnp.fliplr(img)\n","\n","\n","def flip_up_down(img):\n","    \"\"\"Flips an image in up/down direction.\"\"\"\n","    return jnp.flipud(img)\n","\n","\n","def random_rotate(img, rotate):\n","    \"\"\"Randomly rotate an image by 90 degrees.\n","    \n","    Args:\n","        img: Array representing the image\n","        rotate: Boolean for rotating or not\n","    Returns:\n","        Rotated or an identity image\n","    \"\"\"\n","\n","    return jax.lax.cond(rotate, rotate_90, identity, img)\n","\n","\n","def random_horizontal_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_left_right, identity, img)\n","    \n","    \n","def random_vertical_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_up_down, identity, img)\n","\n","\n","\n","\n","\n","# All the above function are written to work on a single example. \n","# We will use `vmap` to get a version of these functions that can\n","# operate on a batch of images. We will also add the `jit` transformation\n","# on top of it so that the whole pipeline can be compiled and executed faster\n","random_rotate_jitted = jit(vmap(random_rotate, in_axes=(0, 0)))\n","random_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\n","random_vertical_flip_jitted = jit(vmap(random_vertical_flip, in_axes=(0, 0)))\n","\n","@jax.jit\n","def augment_images(images, key):\n","    \"\"\"Augment a batch of input images.\n","    \n","    Args:\n","        images: Batch of input images as a jax array\n","        key: Seed/Key for random functions for generating booleans\n","    Returns:\n","        Augmented images with the same shape as the input images\n","    \"\"\"\n","    \n","    batch_size = len(images)\n","    \n","    # 1. Rotation\n","    key, subkey = random.split(key)\n","    rotate = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_rotate_jitted(images, rotate)\n","    \n","    # 2. Flip horizontally\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_horizontal_flip_jitted(augmented, flip)\n","    \n","    # 3. Flip vertically\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_vertical_flip_jitted(augmented, flip)\n","    \n","    return augmented"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.061566,"end_time":"2022-01-04T19:07:21.850018","exception":false,"start_time":"2022-01-04T19:07:21.788452","status":"completed"},"tags":[]},"source":["Perfect! The augmentation pipeline is working as expected. Let's move to the next step.\n","\n","# Data Preprocessing\n","\n","For data preprocessing, we will apply these two things:\n","1. We will normalize the image data so that the pixel values for each image is in the range `[0, 1]`\n","2. We will one-hot encode our labels"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:04.09014Z","iopub.status.busy":"2022-02-13T17:08:04.089306Z","iopub.status.idle":"2022-02-13T17:08:05.791843Z","shell.execute_reply":"2022-02-13T17:08:05.791083Z","shell.execute_reply.started":"2022-02-13T17:08:04.090101Z"},"papermill":{"duration":2.688759,"end_time":"2022-01-04T19:07:24.600434","exception":false,"start_time":"2022-01-04T19:07:21.911675","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images shape:   (50000, 32, 32, 3)  Labels shape: (50000, 10)\n","Validation images shape: (10000, 32, 32, 3)  Labels shape: (10000, 10)\n"]}],"source":["# Normalize the image pixels in the range [0, 1]\n","x_train_normalized = jnp.array(x_train / 255.)\n","x_valid_normalized = jnp.array(x_valid / 255.)\n","\n","# One hot encoding applied to the labels. We have 10\n","# classes in the dataset, hence the depth of OHE would be 10\n","y_train_ohe = jnp.squeeze(jax.nn.one_hot(y_train, num_classes=10))\n","y_valid_ohe = jnp.squeeze(jax.nn.one_hot(y_valid, num_classes=10))\n","\n","print(f\"Training images shape:   {x_train_normalized.shape}  Labels shape: {y_train_ohe.shape}\")\n","print(f\"Validation images shape: {x_valid_normalized.shape}  Labels shape: {y_valid_ohe.shape}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.060709,"end_time":"2022-01-04T19:07:24.724781","exception":false,"start_time":"2022-01-04T19:07:24.664072","status":"completed"},"tags":[]},"source":["# Data Generator\n","\n","Now that we have preprocessed our dataset, we need to define our data generator that will stream batches of data, where each batch is a pair of images and the corresponding labels. We will apply data augmentation to the training data only."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:06.163836Z","iopub.status.busy":"2022-02-13T17:08:06.163471Z","iopub.status.idle":"2022-02-13T17:08:06.990355Z","shell.execute_reply":"2022-02-13T17:08:06.988483Z","shell.execute_reply.started":"2022-02-13T17:08:06.163783Z"},"papermill":{"duration":1.068589,"end_time":"2022-01-04T19:07:25.852618","exception":false,"start_time":"2022-01-04T19:07:24.784029","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch of images is of shape:  (8, 32, 32, 3)\n","Batch of labels is of shape:  (8, 10)\n"]}],"source":["def data_generator(images, labels, batch_size=128, is_valid=False, key=None):\n","    \"\"\"Generates batches of data from a given dataset.\n","    \n","    Args:\n","        images: Image data represented by a ndarray\n","        labels: One-hot enocded labels\n","        batch_size: Number of data points in a single batch\n","        is_valid: (Boolean) If validation data, then don't shuffle and\n","                    don't apply any augmentation\n","        key: PRNG key needed for augmentation\n","    Yields:\n","        Batches of images-labels pairs\n","    \"\"\"\n","    \n","    # 1. Calculate the total number of batches\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    \n","    # 2. Get the indices and shuffle them\n","    indices = np.arange(len(images))\n","    \n","    if not is_valid:\n","        if key is None:\n","             raise ValueError(\"A PRNG key is required if `aug` is set to True\")\n","        else:\n","            np.random.shuffle(indices)\n","    \n","    for batch in range(num_batches):\n","        curr_idx = indices[batch * batch_size: (batch+1) * batch_size]\n","        batch_images = images[curr_idx]\n","        batch_labels = labels[curr_idx]\n","        \n","        if not is_valid: \n","            batch_images = augment_images(batch_images, key=key)\n","        yield batch_images, batch_labels\n","        \n","        \n","\n","# Sanity Check: To make sure that the batches generated by the data\n","# generator are of correct size, we will just pull a batch of data and\n","# will check the shape of the images and the labels\n","\n","sample_data_gen = data_generator(\n","    images=x_train_normalized,\n","    labels=y_train_ohe,\n","    batch_size=8,\n","    is_valid=False,\n","    key=random.PRNGKey(0)\n",")\n","\n","sample_batch_images, sample_batch_labels = next(sample_data_gen)\n","print(\"Batch of images is of shape: \", sample_batch_images.shape)\n","print(\"Batch of labels is of shape: \", sample_batch_labels.shape)\n","\n","# Clean up unnecessary objects\n","del sample_data_gen, sample_batch_images, sample_batch_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.059208,"end_time":"2022-01-04T19:07:25.972317","exception":false,"start_time":"2022-01-04T19:07:25.913109","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from typing import Any\n","\n","\n","class resNet(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = inputs\n","        x = nn.Conv(x.shape[-1], (3, 3), padding=\"SAME\",use_bias=False)(x)\n","        x = nn.Dropout(0.1,deterministic=not IsTrain)(x)\n","        x = nn.BatchNorm(use_running_average=not IsTrain)(x)\n","        x = nn.gelu(x)\n","        return inputs + x\n","\n","class Pool(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = nn.Conv(inputs.shape[-1]*4, (3, 3), (2, 2), padding=\"SAME\",use_bias=False)(inputs)\n","        x = nn.Dropout(0.1,deterministic=not IsTrain)(x)\n","        x = nn.BatchNorm(use_running_average=not IsTrain)(x)\n","        x = nn.gelu(x)\n","        return x\n","    \n","class CifarCNN(nn.Module):\n","    \"\"\"CIFAR-10 Classifier\"\"\"\n","    res_repeats: int = 2\n","    out_repeats: int = 4\n","    @nn.compact\n","    def __call__(self, x, IsTrain):\n","        # First conv block\n","        for _ in range(self.out_repeats):\n","            x = Pool()(x,IsTrain)\n","            for _ in range(self.res_repeats):\n","                x = resNet()(x,IsTrain)        \n","        \n","        # Flatten \n","        x = x.reshape(x.shape[0], -1)\n","        \n","        # Dense layers\n","        \n","        x = nn.Dropout(0.1,deterministic=not IsTrain)(x)\n","        x = nn.BatchNorm(use_running_average=not IsTrain)(x)\n","        # We are going to return the logits and not\n","        # the softamx activations \n","        x = nn.Dense(10)(x)\n","        return x\n","    \n","model = CifarCNN()\n","params = model.init({'params':random.PRNGKey(2),'dropout':random.PRNGKey(3)},jnp.ones([1, 32, 32, 3]),True)\n","states,params = params.pop('params')\n","opt = optax.adam(learning_rate=1e-2)\n","opt_states = opt.init(params)\n","combined_states = freeze({'params':params,**states})\n","\n","@jax.jit\n","def train_one_step(x,y,combined_states,opt_states,dropout_key):\n","    return_key,dropout_key = random.split(dropout_key,2)\n","    states,params = combined_states.pop('params')\n","    def loss_fn(params):\n","        yhat,new_states = model.apply({'params':params,**states},x,True,\\\n","                                   mutable='batch_stats',rngs={'dropout':dropout_key})\n","        loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","        metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","        return loss,(new_states,metric)\n","    grad_fn = jax.value_and_grad(loss_fn,has_aux=True)\n","    (l,(states,metric)),grads = grad_fn(params)\n","    updates, opt_states = opt.update(grads, opt_states)\n","    params = optax.apply_updates(params, updates)\n","    combined_states = freeze({'params':params,**states})\n","    return combined_states,opt_states,return_key,l,metric\n","\n","@jax.jit\n","def eval_one_step(x,y,combined_states):\n","    yhat = model.apply(combined_states,x,False)\n","    loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","    metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","    return loss, metric"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","We have coded every piece required for training and evaluation. We will now define our training loop. "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:07.907825Z","iopub.status.busy":"2022-02-13T17:08:07.907072Z","iopub.status.idle":"2022-02-13T17:11:01.365961Z","shell.execute_reply":"2022-02-13T17:11:01.365104Z","shell.execute_reply.started":"2022-02-13T17:08:07.90777Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:0, loss: 3.086, acc: 0.219, valid_loss: 2.008, valid_acc: 0.238\n","epoch:1, loss: 2.193, acc: 0.307, valid_loss: 1.813, valid_acc: 0.261\n","epoch:2, loss: 1.828, acc: 0.375, valid_loss: 1.670, valid_acc: 0.328\n","epoch:3, loss: 1.642, acc: 0.415, valid_loss: 1.725, valid_acc: 0.378\n","epoch:4, loss: 1.540, acc: 0.446, valid_loss: 1.434, valid_acc: 0.442\n","epoch:5, loss: 1.472, acc: 0.470, valid_loss: 1.483, valid_acc: 0.466\n","epoch:6, loss: 1.404, acc: 0.495, valid_loss: 1.507, valid_acc: 0.470\n","epoch:7, loss: 1.336, acc: 0.522, valid_loss: 1.496, valid_acc: 0.527\n","epoch:8, loss: 1.265, acc: 0.548, valid_loss: 1.272, valid_acc: 0.490\n","epoch:9, loss: 1.215, acc: 0.568, valid_loss: 1.156, valid_acc: 0.524\n","epoch:10, loss: 1.176, acc: 0.581, valid_loss: 0.989, valid_acc: 0.565\n","epoch:11, loss: 1.144, acc: 0.594, valid_loss: 1.183, valid_acc: 0.557\n","epoch:12, loss: 1.119, acc: 0.603, valid_loss: 1.250, valid_acc: 0.545\n","epoch:13, loss: 1.107, acc: 0.610, valid_loss: 1.176, valid_acc: 0.536\n","epoch:14, loss: 1.089, acc: 0.619, valid_loss: 0.944, valid_acc: 0.571\n","epoch:15, loss: 1.059, acc: 0.628, valid_loss: 0.957, valid_acc: 0.604\n","epoch:16, loss: 1.055, acc: 0.630, valid_loss: 1.051, valid_acc: 0.536\n","epoch:17, loss: 1.012, acc: 0.645, valid_loss: 0.989, valid_acc: 0.579\n","epoch:18, loss: 0.989, acc: 0.654, valid_loss: 1.040, valid_acc: 0.628\n","epoch:19, loss: 0.977, acc: 0.659, valid_loss: 0.866, valid_acc: 0.513\n","epoch:20, loss: 0.958, acc: 0.666, valid_loss: 0.786, valid_acc: 0.614\n","epoch:21, loss: 0.941, acc: 0.673, valid_loss: 0.789, valid_acc: 0.593\n","epoch:22, loss: 0.930, acc: 0.677, valid_loss: 0.846, valid_acc: 0.605\n","epoch:23, loss: 0.913, acc: 0.683, valid_loss: 0.912, valid_acc: 0.648\n","epoch:24, loss: 0.906, acc: 0.685, valid_loss: 1.073, valid_acc: 0.614\n","epoch:25, loss: 0.879, acc: 0.696, valid_loss: 0.949, valid_acc: 0.619\n","epoch:26, loss: 0.869, acc: 0.698, valid_loss: 0.877, valid_acc: 0.659\n","epoch:27, loss: 0.861, acc: 0.703, valid_loss: 0.762, valid_acc: 0.643\n","epoch:28, loss: 0.847, acc: 0.706, valid_loss: 0.987, valid_acc: 0.600\n","epoch:29, loss: 0.833, acc: 0.711, valid_loss: 0.589, valid_acc: 0.651\n","epoch:30, loss: 0.821, acc: 0.716, valid_loss: 0.865, valid_acc: 0.595\n","epoch:31, loss: 0.812, acc: 0.719, valid_loss: 0.784, valid_acc: 0.642\n","epoch:32, loss: 0.800, acc: 0.724, valid_loss: 0.870, valid_acc: 0.657\n","epoch:33, loss: 0.795, acc: 0.727, valid_loss: 0.755, valid_acc: 0.638\n","epoch:34, loss: 0.789, acc: 0.731, valid_loss: 0.951, valid_acc: 0.636\n","epoch:35, loss: 0.773, acc: 0.734, valid_loss: 0.877, valid_acc: 0.650\n","epoch:36, loss: 0.769, acc: 0.734, valid_loss: 0.596, valid_acc: 0.679\n","epoch:37, loss: 0.759, acc: 0.739, valid_loss: 0.838, valid_acc: 0.670\n","epoch:38, loss: 0.738, acc: 0.746, valid_loss: 0.737, valid_acc: 0.671\n","epoch:39, loss: 0.745, acc: 0.744, valid_loss: 0.753, valid_acc: 0.685\n","epoch:40, loss: 0.728, acc: 0.750, valid_loss: 0.879, valid_acc: 0.677\n","epoch:41, loss: 0.715, acc: 0.752, valid_loss: 0.721, valid_acc: 0.671\n","epoch:42, loss: 0.709, acc: 0.755, valid_loss: 0.807, valid_acc: 0.655\n","epoch:43, loss: 0.713, acc: 0.758, valid_loss: 0.857, valid_acc: 0.675\n","epoch:44, loss: 0.696, acc: 0.764, valid_loss: 0.674, valid_acc: 0.658\n","epoch:45, loss: 0.689, acc: 0.762, valid_loss: 0.813, valid_acc: 0.655\n","epoch:46, loss: 0.682, acc: 0.766, valid_loss: 0.729, valid_acc: 0.639\n","epoch:47, loss: 0.685, acc: 0.764, valid_loss: 0.754, valid_acc: 0.626\n","epoch:48, loss: 0.669, acc: 0.771, valid_loss: 0.655, valid_acc: 0.681\n","epoch:49, loss: 0.661, acc: 0.772, valid_loss: 0.817, valid_acc: 0.675\n"]}],"source":["EPOCHS = 50\n","BATCH_SIZE = 128\n","num_train_batches = len(x_train) // BATCH_SIZE\n","num_valid_batches = len(x_valid) // BATCH_SIZE\n","\n","key = random.PRNGKey(0)\n","key, dropout_key = random.split(key)\n","\n","    \n","for i in range(EPOCHS):\n","    train_data_gen = data_generator(x_train_normalized,\n","                            y_train_ohe,\n","                            batch_size=BATCH_SIZE,\n","                            is_valid=False,\n","                            key=key\n","                           )\n","    valid_data_gen = data_generator(x_valid_normalized,\n","                               y_valid_ohe,\n","                               batch_size=BATCH_SIZE,\n","                               is_valid=True\n","                               )\n","    # train\n","    train_batch_loss = 0\n","    train_batch_metric = 0\n","    for step in range(num_train_batches):\n","        x,y = next(train_data_gen)\n","        combined_states,opt_states,dropout_key,l,metric = train_one_step(x,y,combined_states,opt_states,dropout_key)\n","        train_batch_loss += l\n","        train_batch_metric += metric\n","    train_batch_loss/=num_train_batches\n","    train_batch_metric/=num_train_batches\n","    \n","    # eval\n","    eval_batch_loss = 0\n","    eval_batch_metric = 0\n","    for step in range(num_valid_batches):\n","        x,y = next(valid_data_gen)\n","        loss, metric = eval_one_step(x,y,combined_states)\n","        eval_batch_loss += l\n","        eval_batch_metric += metric\n","    eval_batch_loss/=num_valid_batches\n","    eval_batch_metric/=num_valid_batches\n","    \n","    print(f\"epoch:{i}, loss: {train_batch_loss:.3f}, acc: {train_batch_metric:.3f}, valid_loss: {eval_batch_loss:.3f}, valid_acc: {eval_batch_metric:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
