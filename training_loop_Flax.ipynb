{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.040794,"end_time":"2022-01-04T19:06:57.340525","exception":false,"start_time":"2022-01-04T19:06:57.299731","status":"completed"},"tags":[]},"source":["Modified based on https://www.kaggle.com/code/aakashnain/building-models-in-jax-part2-flax#Evaluation\n","\n","Showcase:\n","1. Train model with BatchNorm and Dropout (how to track/update states for BN and how to update key for dropout)\n","2. Train_one_step & eval_one_step\n","3. How to change between Training and Eval mode"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:51:49.527320Z","iopub.status.busy":"2023-07-11T16:51:49.526581Z","iopub.status.idle":"2023-07-11T16:51:49.559731Z","shell.execute_reply":"2023-07-11T16:51:49.558856Z","shell.execute_reply.started":"2023-07-11T16:51:49.527224Z"},"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-11T16:53:42.356175Z","iopub.status.busy":"2023-07-11T16:53:42.355854Z","iopub.status.idle":"2023-07-11T16:53:50.661530Z","shell.execute_reply":"2023-07-11T16:53:50.660627Z","shell.execute_reply.started":"2023-07-11T16:53:42.356139Z"},"papermill":{"duration":7.602287,"end_time":"2022-01-04T19:07:04.983064","exception":false,"start_time":"2022-01-04T19:06:57.380777","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.datasets import cifar10\n","from flax.core import freeze, unfreeze\n","import jax\n","import jax.numpy as jnp\n","from jax import random\n","from jax import make_jaxpr\n","from jax.config import config\n","from jax import value_and_grad\n","from jax import grad, vmap, pmap, jit\n","\n","import optax\n","from flax import linen as nn\n","from flax.training import train_state\n","\n","np.random.seed(1234)\n","%config IPCompleter.use_jedi = False"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.022962,"end_time":"2022-01-04T19:07:05.029004","exception":false,"start_time":"2022-01-04T19:07:05.006042","status":"completed"},"tags":[]},"source":["# Dataset\n","\n","We will use the Cifar-10 dataset for this experiment. You can download it or add it from Kaggle as well, but I am directly importing it from the available `tf.keras.datasets` for the sake of simplicity and brevity"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T16:54:08.284072Z","iopub.status.busy":"2023-07-11T16:54:08.283736Z","iopub.status.idle":"2023-07-11T16:54:21.895655Z","shell.execute_reply":"2023-07-11T16:54:21.894706Z","shell.execute_reply.started":"2023-07-11T16:54:08.284036Z"},"papermill":{"duration":9.318512,"end_time":"2022-01-04T19:07:14.370367","exception":false,"start_time":"2022-01-04T19:07:05.051855","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of training samples: 50000 with samples shape: (32, 32, 3)\n","Number of validation samples: 10000 with samples shape: (32, 32, 3)\n"]}],"source":["# The downloaded dataset consists of two tuples. The first\n","# tuple represents the training data consisting of pairs of images\n","# and labels. Similary, the second tuple consists of validation/test data.\n","# I will use the second tuple as the validation data for this demo\n","\n","(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\n","print(f\"\\nNumber of training samples: {len(x_train)} with samples shape: {x_train.shape[1:]}\")\n","print(f\"Number of validation samples: {len(x_valid)} with samples shape: {x_valid.shape[1:]}\")\n","\n","\n","# There are 10 classes in this dataset. We will create a dictionary for\n","# mapping the names of the classes represented by the integer labels\n","# Labels dictionary\n","labels_dict = {\n","    0: \"airplane\",\n","    1: \"automobile\",\n","    2: \"bird\",\n","    3: \"cat\",\n","    4: \"deer\",\n","    5: \"dog\",\n","    6: \"frog\",\n","    7: \"horse\",\n","    8: \"ship\",\n","    9: \"truck\"\n","}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.055043,"end_time":"2022-01-04T19:07:15.683699","exception":false,"start_time":"2022-01-04T19:07:15.628656","status":"completed"},"tags":[]},"source":["# Data Augmentation\n","\n","We will apply image augmentation, and that too, purely in JAX. For augmentation, we will be using three different augmentation techniques:\n","1. Random rotation by 90 degrees\n","2. Random horizontal flips\n","3. Random vertical flips\n","\n","For each of these augmentations:\n","1. We will define a function that will either return an augmented image or an identity image\n","2. Use [**vmap**](https://www.kaggle.com/aakashnain/tf-jax-tutorials-part-8-vmap-pmap#Data-Augmentation---Building-a-simple,-fast,-and-scalable-pipeline) to do augmentation in batches\n","3. [**jit**](https://www.kaggle.com/aakashnain/tf-jax-tutorials-part-7-jit-in-jax) the whole augmentation pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:07:57.857213Z","iopub.status.busy":"2022-02-13T17:07:57.856965Z","iopub.status.idle":"2022-02-13T17:07:57.871954Z","shell.execute_reply":"2022-02-13T17:07:57.87131Z","shell.execute_reply.started":"2022-02-13T17:07:57.857176Z"},"papermill":{"duration":0.269247,"end_time":"2022-01-04T19:07:16.006937","exception":false,"start_time":"2022-01-04T19:07:15.73769","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def rotate_90(img):\n","    \"\"\"Rotates an image by 90 degress k times.\"\"\"\n","    return jnp.rot90(img, k=1, axes=(0, 1))\n","\n","\n","def identity(img):\n","    \"\"\"Returns an image as it is.\"\"\"\n","    return img\n","\n","\n","def flip_left_right(img):\n","    \"\"\"Flips an image left/right direction.\"\"\"\n","    return jnp.fliplr(img)\n","\n","\n","def flip_up_down(img):\n","    \"\"\"Flips an image in up/down direction.\"\"\"\n","    return jnp.flipud(img)\n","\n","\n","def random_rotate(img, rotate):\n","    \"\"\"Randomly rotate an image by 90 degrees.\n","    \n","    Args:\n","        img: Array representing the image\n","        rotate: Boolean for rotating or not\n","    Returns:\n","        Rotated or an identity image\n","    \"\"\"\n","\n","    return jax.lax.cond(rotate, rotate_90, identity, img)\n","\n","\n","def random_horizontal_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_left_right, identity, img)\n","    \n","    \n","def random_vertical_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_up_down, identity, img)\n","\n","\n","\n","\n","\n","# All the above function are written to work on a single example. \n","# We will use `vmap` to get a version of these functions that can\n","# operate on a batch of images. We will also add the `jit` transformation\n","# on top of it so that the whole pipeline can be compiled and executed faster\n","random_rotate_jitted = jit(vmap(random_rotate, in_axes=(0, 0)))\n","random_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\n","random_vertical_flip_jitted = jit(vmap(random_vertical_flip, in_axes=(0, 0)))\n","\n","@jax.jit\n","def augment_images(images, key):\n","    \"\"\"Augment a batch of input images.\n","    \n","    Args:\n","        images: Batch of input images as a jax array\n","        key: Seed/Key for random functions for generating booleans\n","    Returns:\n","        Augmented images with the same shape as the input images\n","    \"\"\"\n","    \n","    batch_size = len(images)\n","    \n","    # 1. Rotation\n","    key, subkey = random.split(key)\n","    rotate = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_rotate_jitted(images, rotate)\n","    \n","    # 2. Flip horizontally\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_horizontal_flip_jitted(augmented, flip)\n","    \n","    # 3. Flip vertically\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_vertical_flip_jitted(augmented, flip)\n","    \n","    return augmented"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.061566,"end_time":"2022-01-04T19:07:21.850018","exception":false,"start_time":"2022-01-04T19:07:21.788452","status":"completed"},"tags":[]},"source":["Perfect! The augmentation pipeline is working as expected. Let's move to the next step.\n","\n","# Data Preprocessing\n","\n","For data preprocessing, we will apply these two things:\n","1. We will normalize the image data so that the pixel values for each image is in the range `[0, 1]`\n","2. We will one-hot encode our labels"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:04.09014Z","iopub.status.busy":"2022-02-13T17:08:04.089306Z","iopub.status.idle":"2022-02-13T17:08:05.791843Z","shell.execute_reply":"2022-02-13T17:08:05.791083Z","shell.execute_reply.started":"2022-02-13T17:08:04.090101Z"},"papermill":{"duration":2.688759,"end_time":"2022-01-04T19:07:24.600434","exception":false,"start_time":"2022-01-04T19:07:21.911675","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images shape:   (50000, 32, 32, 3)  Labels shape: (50000, 10)\n","Validation images shape: (10000, 32, 32, 3)  Labels shape: (10000, 10)\n"]}],"source":["# Normalize the image pixels in the range [0, 1]\n","x_train_normalized = jnp.array(x_train / 255.)\n","x_valid_normalized = jnp.array(x_valid / 255.)\n","\n","# One hot encoding applied to the labels. We have 10\n","# classes in the dataset, hence the depth of OHE would be 10\n","y_train_ohe = jnp.squeeze(jax.nn.one_hot(y_train, num_classes=10))\n","y_valid_ohe = jnp.squeeze(jax.nn.one_hot(y_valid, num_classes=10))\n","\n","print(f\"Training images shape:   {x_train_normalized.shape}  Labels shape: {y_train_ohe.shape}\")\n","print(f\"Validation images shape: {x_valid_normalized.shape}  Labels shape: {y_valid_ohe.shape}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.060709,"end_time":"2022-01-04T19:07:24.724781","exception":false,"start_time":"2022-01-04T19:07:24.664072","status":"completed"},"tags":[]},"source":["# Data Generator\n","\n","Now that we have preprocessed our dataset, we need to define our data generator that will stream batches of data, where each batch is a pair of images and the corresponding labels. We will apply data augmentation to the training data only."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:06.163836Z","iopub.status.busy":"2022-02-13T17:08:06.163471Z","iopub.status.idle":"2022-02-13T17:08:06.990355Z","shell.execute_reply":"2022-02-13T17:08:06.988483Z","shell.execute_reply.started":"2022-02-13T17:08:06.163783Z"},"papermill":{"duration":1.068589,"end_time":"2022-01-04T19:07:25.852618","exception":false,"start_time":"2022-01-04T19:07:24.784029","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def identity(img):\n","    \"\"\"Returns an image as it is.\"\"\"\n","    return img\n","\n","\n","def flip_left_right(img):\n","    \"\"\"Flips an image left/right direction.\"\"\"\n","    return jnp.fliplr(img)\n","\n","\n","def random_horizontal_flip(img, flip):\n","    \"\"\"Randomly flip an image vertically.\n","    \n","    Args:\n","        img: Array representing the image\n","        flip: Boolean for flipping or not\n","    Returns:\n","        Flipped or an identity image\n","    \"\"\"\n","    \n","    return jax.lax.cond(flip, flip_left_right, identity, img)\n","    \n","\n","\n","\n","# All the above function are written to work on a single example. \n","# We will use `vmap` to get a version of these functions that can\n","# operate on a batch of images. We will also add the `jit` transformation\n","# on top of it so that the whole pipeline can be compiled and executed faster\n","random_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\n","\n","\n","@jax.jit\n","def augment_images(images, key):\n","    \"\"\"Augment a batch of input images.\n","    \n","    Args:\n","        images: Batch of input images as a jax array\n","        key: Seed/Key for random functions for generating booleans\n","    Returns:\n","        Augmented images with the same shape as the input images\n","    \"\"\"\n","    \n","    batch_size = len(images)\n","    \n","    # 2. Flip horizontally\n","    key, subkey = random.split(key)\n","    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n","    augmented = random_horizontal_flip_jitted(images, flip)\n","    return augmented"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch of images is of shape:  (8, 32, 32, 3)\n","Batch of labels is of shape:  (8, 10)\n"]}],"source":["def data_generator(images, labels, batch_size=128, is_valid=False, key=None):\n","    \"\"\"Generates batches of data from a given dataset.\n","    \n","    Args:\n","        images: Image data represented by a ndarray\n","        labels: One-hot enocded labels\n","        batch_size: Number of data points in a single batch\n","        is_valid: (Boolean) If validation data, then don't shuffle and\n","                    don't apply any augmentation\n","        key: PRNG key needed for augmentation\n","    Yields:\n","        Batches of images-labels pairs\n","    \"\"\"\n","    \n","    # 1. Calculate the total number of batches\n","    num_batches = int(np.ceil(len(images) / batch_size))\n","    \n","    # 2. Get the indices and shuffle them\n","    indices = np.arange(len(images))\n","    \n","    if not is_valid:\n","        if key is None:\n","             raise ValueError(\"A PRNG key is required if `aug` is set to True\")\n","        else:\n","            np.random.shuffle(indices)\n","    \n","    for batch in range(num_batches):\n","        curr_idx = indices[batch * batch_size: (batch+1) * batch_size]\n","        batch_images = images[curr_idx]\n","        batch_labels = labels[curr_idx]\n","        \n","        if not is_valid: \n","            batch_images = augment_images(batch_images, key=key)\n","        yield batch_images, batch_labels\n","        \n","        \n","\n","# Sanity Check: To make sure that the batches generated by the data\n","# generator are of correct size, we will just pull a batch of data and\n","# will check the shape of the images and the labels\n","\n","sample_data_gen = data_generator(\n","    images=x_train_normalized,\n","    labels=y_train_ohe,\n","    batch_size=8,\n","    is_valid=False,\n","    key=random.PRNGKey(0)\n",")\n","\n","sample_batch_images, sample_batch_labels = next(sample_data_gen)\n","print(\"Batch of images is of shape: \", sample_batch_images.shape)\n","print(\"Batch of labels is of shape: \", sample_batch_labels.shape)\n","\n","# Clean up unnecessary objects\n","del sample_data_gen, sample_batch_images, sample_batch_labels"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.059208,"end_time":"2022-01-04T19:07:25.972317","exception":false,"start_time":"2022-01-04T19:07:25.913109","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from typing import Any\n","\n","\n","class resNet(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = inputs\n","        x = nn.Conv(x.shape[-1], (3, 3), padding=\"SAME\",use_bias=False)(x)\n","        x = nn.Dropout(0.1,deterministic=not IsTrain)(x)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        x = nn.gelu(x)\n","        return inputs + x\n","\n","class Pool(nn.Module):\n","    \n","    @nn.compact\n","    def __call__(self, inputs, IsTrain):\n","        x = nn.Conv(inputs.shape[-1]*4, (3, 3), (2, 2), padding=\"SAME\",use_bias=False)(inputs)\n","        x = nn.Dropout(0.1,deterministic=not IsTrain)(x)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        x = nn.gelu(x)\n","        return x\n","    \n","class CifarCNN(nn.Module):\n","    \"\"\"CIFAR-10 Classifier\"\"\"\n","    res_repeats: int = 3\n","    out_repeats: int = 4\n","    @nn.compact\n","    def __call__(self, x, IsTrain):\n","        x = Pool()(x,IsTrain)\n","        for _ in range(self.out_repeats):\n","            x = Pool()(x,IsTrain)\n","            for _ in range(self.res_repeats):\n","                x = resNet()(x,IsTrain)\n","        # Flatten \n","        x = x.reshape(x.shape[0], -1)\n","        # Dense layers\n","        x = nn.Dropout(0.1)(x,deterministic=not IsTrain)\n","        x = nn.BatchNorm()(x,use_running_average=not IsTrain)\n","        # We are going to return the logits and not\n","        # the softamx activations \n","        x = nn.Dense(10)(x)\n","        return x\n","\n","EPOCHS = 200\n","BATCH_SIZE = 128\n","num_train_batches = len(x_train) // BATCH_SIZE\n","num_valid_batches = len(x_valid) // BATCH_SIZE\n","total_steps = EPOCHS * num_train_batches\n","\n","model = CifarCNN()\n","params = model.init({'params':random.PRNGKey(2),'dropout':random.PRNGKey(3)},jnp.ones([1, 32, 32, 3]),True)\n","states,params = params.pop('params')\n","# _scheduler = optax.piecewise_constant_schedule(init_value=1e-2,\n","#                                                boundaries_and_scales={int(total_steps*0.6):0.25,\n","#                                                                       int(total_steps*0.85):0.25})\n","opt = optax.adamw(learning_rate=1e-2)\n","opt_states = opt.init(params)\n","combined_states = freeze({'params':params,**states})\n","\n","@jax.jit\n","def train_one_step(x,y,combined_states,opt_states,dropout_key):\n","    return_key,dropout_key = random.split(dropout_key,2)\n","    states,params = combined_states.pop('params')\n","    def loss_fn(params):\n","        yhat,new_states = model.apply({'params':params,**states},x,True,\\\n","                                   mutable='batch_stats',rngs={'dropout':dropout_key})\n","        loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","        metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","        return loss,(new_states,metric)\n","    grad_fn = jax.value_and_grad(loss_fn,has_aux=True)\n","    (l,(states,metric)),grads = grad_fn(params)\n","    updates, opt_states = opt.update(grads, opt_states,params=params)\n","    params = optax.apply_updates(params, updates)\n","    combined_states = freeze({'params':params,**states})\n","    return combined_states,opt_states,return_key,l,metric\n","\n","@jax.jit\n","def eval_one_step(x,y,combined_states):\n","    yhat = model.apply(combined_states,x,False)\n","    loss = jnp.mean(optax.softmax_cross_entropy(logits=yhat, labels=y))\n","    metric = jnp.mean(jnp.argmax(yhat,-1) == jnp.argmax(y,-1))\n","    return loss, metric"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","We have coded every piece required for training and evaluation. We will now define our training loop. "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-13T17:08:07.907825Z","iopub.status.busy":"2022-02-13T17:08:07.907072Z","iopub.status.idle":"2022-02-13T17:11:01.365961Z","shell.execute_reply":"2022-02-13T17:11:01.365104Z","shell.execute_reply.started":"2022-02-13T17:08:07.90777Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:0, loss: 3.171, acc: 0.204, valid_loss: 2.297, valid_acc: 0.164\n","epoch:1, loss: 2.044, acc: 0.329, valid_loss: 1.872, valid_acc: 0.390\n","epoch:2, loss: 1.632, acc: 0.421, valid_loss: 1.524, valid_acc: 0.429\n","epoch:3, loss: 1.393, acc: 0.500, valid_loss: 1.303, valid_acc: 0.531\n","epoch:4, loss: 1.227, acc: 0.561, valid_loss: 1.141, valid_acc: 0.573\n","epoch:5, loss: 1.123, acc: 0.604, valid_loss: 0.985, valid_acc: 0.616\n","epoch:6, loss: 1.018, acc: 0.639, valid_loss: 1.047, valid_acc: 0.612\n","epoch:7, loss: 0.940, acc: 0.668, valid_loss: 0.967, valid_acc: 0.663\n","epoch:8, loss: 0.862, acc: 0.698, valid_loss: 0.888, valid_acc: 0.637\n","epoch:9, loss: 0.789, acc: 0.721, valid_loss: 0.936, valid_acc: 0.687\n","epoch:10, loss: 0.727, acc: 0.744, valid_loss: 0.722, valid_acc: 0.726\n","epoch:11, loss: 0.671, acc: 0.767, valid_loss: 0.557, valid_acc: 0.720\n","epoch:12, loss: 0.620, acc: 0.783, valid_loss: 0.655, valid_acc: 0.732\n","epoch:13, loss: 0.570, acc: 0.802, valid_loss: 0.678, valid_acc: 0.728\n","epoch:14, loss: 0.528, acc: 0.816, valid_loss: 0.445, valid_acc: 0.749\n","epoch:15, loss: 0.490, acc: 0.829, valid_loss: 0.321, valid_acc: 0.757\n","epoch:16, loss: 0.445, acc: 0.844, valid_loss: 0.425, valid_acc: 0.754\n","epoch:17, loss: 0.412, acc: 0.856, valid_loss: 0.359, valid_acc: 0.747\n","epoch:18, loss: 0.372, acc: 0.871, valid_loss: 0.325, valid_acc: 0.759\n","epoch:19, loss: 0.342, acc: 0.882, valid_loss: 0.331, valid_acc: 0.760\n","epoch:20, loss: 0.320, acc: 0.889, valid_loss: 0.361, valid_acc: 0.749\n","epoch:21, loss: 0.293, acc: 0.899, valid_loss: 0.276, valid_acc: 0.766\n","epoch:22, loss: 0.290, acc: 0.901, valid_loss: 0.291, valid_acc: 0.774\n","epoch:23, loss: 0.259, acc: 0.912, valid_loss: 0.296, valid_acc: 0.751\n","epoch:24, loss: 0.240, acc: 0.917, valid_loss: 0.333, valid_acc: 0.766\n","epoch:25, loss: 0.232, acc: 0.921, valid_loss: 0.311, valid_acc: 0.758\n","epoch:26, loss: 0.293, acc: 0.908, valid_loss: 0.510, valid_acc: 0.739\n","epoch:27, loss: 0.442, acc: 0.866, valid_loss: 0.241, valid_acc: 0.773\n","epoch:28, loss: 0.194, acc: 0.933, valid_loss: 0.281, valid_acc: 0.772\n","epoch:29, loss: 0.165, acc: 0.942, valid_loss: 0.153, valid_acc: 0.761\n","epoch:30, loss: 0.157, acc: 0.946, valid_loss: 0.195, valid_acc: 0.768\n","epoch:31, loss: 0.148, acc: 0.950, valid_loss: 0.220, valid_acc: 0.764\n","epoch:32, loss: 0.153, acc: 0.947, valid_loss: 0.190, valid_acc: 0.765\n","epoch:33, loss: 0.153, acc: 0.949, valid_loss: 0.117, valid_acc: 0.769\n","epoch:34, loss: 0.156, acc: 0.947, valid_loss: 0.145, valid_acc: 0.751\n","epoch:35, loss: 0.164, acc: 0.944, valid_loss: 0.228, valid_acc: 0.769\n","epoch:36, loss: 0.153, acc: 0.948, valid_loss: 0.110, valid_acc: 0.771\n","epoch:37, loss: 0.143, acc: 0.952, valid_loss: 0.242, valid_acc: 0.737\n","epoch:38, loss: 0.369, acc: 0.898, valid_loss: 1.853, valid_acc: 0.741\n","epoch:39, loss: 0.150, acc: 0.948, valid_loss: 0.133, valid_acc: 0.784\n","epoch:40, loss: 0.126, acc: 0.958, valid_loss: 0.068, valid_acc: 0.783\n","epoch:41, loss: 0.107, acc: 0.963, valid_loss: 0.085, valid_acc: 0.785\n","epoch:42, loss: 0.105, acc: 0.964, valid_loss: 0.097, valid_acc: 0.780\n","epoch:43, loss: 0.104, acc: 0.966, valid_loss: 0.127, valid_acc: 0.772\n","epoch:44, loss: 0.109, acc: 0.963, valid_loss: 0.221, valid_acc: 0.772\n","epoch:45, loss: 0.121, acc: 0.959, valid_loss: 0.211, valid_acc: 0.777\n","epoch:46, loss: 0.125, acc: 0.959, valid_loss: 0.126, valid_acc: 0.751\n","epoch:47, loss: 0.314, acc: 0.912, valid_loss: 0.294, valid_acc: 0.629\n","epoch:48, loss: 0.200, acc: 0.936, valid_loss: 0.218, valid_acc: 0.776\n","epoch:49, loss: 0.105, acc: 0.964, valid_loss: 0.071, valid_acc: 0.775\n","epoch:50, loss: 0.095, acc: 0.969, valid_loss: 0.254, valid_acc: 0.780\n","epoch:51, loss: 0.093, acc: 0.970, valid_loss: 0.086, valid_acc: 0.789\n","epoch:52, loss: 0.091, acc: 0.970, valid_loss: 0.241, valid_acc: 0.773\n","epoch:53, loss: 0.094, acc: 0.968, valid_loss: 0.016, valid_acc: 0.775\n","epoch:54, loss: 0.092, acc: 0.969, valid_loss: 0.294, valid_acc: 0.774\n","epoch:55, loss: 0.103, acc: 0.967, valid_loss: 0.090, valid_acc: 0.772\n","epoch:56, loss: 0.125, acc: 0.961, valid_loss: 0.069, valid_acc: 0.780\n","epoch:57, loss: 0.091, acc: 0.970, valid_loss: 0.062, valid_acc: 0.777\n","epoch:58, loss: 0.090, acc: 0.970, valid_loss: 0.130, valid_acc: 0.782\n","epoch:59, loss: 0.095, acc: 0.969, valid_loss: 0.077, valid_acc: 0.782\n","epoch:60, loss: 0.088, acc: 0.971, valid_loss: 0.052, valid_acc: 0.779\n","epoch:61, loss: 0.100, acc: 0.968, valid_loss: 0.091, valid_acc: 0.780\n","epoch:62, loss: 0.099, acc: 0.969, valid_loss: 0.103, valid_acc: 0.775\n","epoch:63, loss: 0.096, acc: 0.968, valid_loss: 0.048, valid_acc: 0.778\n","epoch:64, loss: 0.097, acc: 0.969, valid_loss: 0.178, valid_acc: 0.773\n","epoch:65, loss: 0.107, acc: 0.968, valid_loss: 0.110, valid_acc: 0.774\n","epoch:66, loss: 0.104, acc: 0.968, valid_loss: 0.063, valid_acc: 0.783\n","epoch:67, loss: 0.083, acc: 0.973, valid_loss: 0.062, valid_acc: 0.774\n","epoch:68, loss: 0.091, acc: 0.971, valid_loss: 0.094, valid_acc: 0.764\n","epoch:69, loss: 0.174, acc: 0.952, valid_loss: 0.194, valid_acc: 0.577\n","epoch:70, loss: 0.157, acc: 0.954, valid_loss: 0.140, valid_acc: 0.773\n","epoch:71, loss: 0.222, acc: 0.933, valid_loss: 0.073, valid_acc: 0.778\n","epoch:72, loss: 0.093, acc: 0.969, valid_loss: 0.051, valid_acc: 0.782\n","epoch:73, loss: 0.062, acc: 0.979, valid_loss: 0.066, valid_acc: 0.786\n","epoch:74, loss: 0.056, acc: 0.981, valid_loss: 0.101, valid_acc: 0.782\n"]}],"source":["key = random.PRNGKey(0)\n","key, dropout_key = random.split(key)\n","\n","    \n","for i in range(EPOCHS):\n","    train_data_gen = data_generator(x_train_normalized,\n","                            y_train_ohe,\n","                            batch_size=BATCH_SIZE,\n","                            is_valid=False,\n","                            key=key\n","                           )\n","    valid_data_gen = data_generator(x_valid_normalized,\n","                               y_valid_ohe,\n","                               batch_size=BATCH_SIZE,\n","                               is_valid=True\n","                               )\n","    # train\n","    train_batch_loss = 0\n","    train_batch_metric = 0\n","    for step in range(num_train_batches):\n","        x,y = next(train_data_gen)\n","        combined_states,opt_states,dropout_key,l,metric = train_one_step(x,y,combined_states,opt_states,dropout_key)\n","        train_batch_loss += l\n","        train_batch_metric += metric\n","    train_batch_loss/=num_train_batches\n","    train_batch_metric/=num_train_batches\n","    \n","    # eval\n","    eval_batch_loss = 0\n","    eval_batch_metric = 0\n","    for step in range(num_valid_batches):\n","        x,y = next(valid_data_gen)\n","        loss, metric = eval_one_step(x,y,combined_states)\n","        eval_batch_loss += l\n","        eval_batch_metric += metric\n","    eval_batch_loss/=num_valid_batches\n","    eval_batch_metric/=num_valid_batches\n","    \n","    print(f\"epoch:{i}, loss: {train_batch_loss:.3f}, acc: {train_batch_metric:.3f}, valid_loss: {eval_batch_loss:.3f}, valid_acc: {eval_batch_metric:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
